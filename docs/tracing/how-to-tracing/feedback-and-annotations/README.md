---
description: >-
  Phoenix supports adding Feedback and Annotations to your traces in a variety
  of ways, include generating LLM evaluation labels and logging human
  annotations.
---

# Feedback & Annotations

## Guides

* To learn how to add human labels to your traces, either manually or programmatically, see [capture-feedback.md](capture-feedback.md "mention")
* To learn how to evaluate traces captured in Phoenix, see [evaluating-phoenix-traces.md](evaluating-phoenix-traces.md "mention")
* To learn how to upload your own evaluation labels into Phoenix, see [llm-evaluations.md](llm-evaluations.md "mention")

For more background on the concept of annotations, see [how-to-annotate-traces.md](../../features-tracing/how-to-annotate-traces.md "mention")

## Types of Feedback & Annotations

Common types of feedback include:

1. LLM as a Judge generated evaluations
2. Code evaluations
3. End user :thumbsup: :thumbsdown: feedback
4. Human labels / human annotations

<figure><img src="https://storage.googleapis.com/arize-assets/phoenix/assets/images/annotation_flow.gif" alt=""><figcaption><p>Adding manual annotations to traces</p></figcaption></figure>
