{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
    "        <br>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Tracing CrewAI with Arize Phoenix - Orchestrator Workers Workflow</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q  'arize-phoenix==11.24.0' opentelemetry-sdk opentelemetry-exporter-otlp crewai crewai_tools openinference-instrumentation-crewai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-gPdVmIndw9"
   },
   "source": [
    "# Set up Keys and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For this colab you'll need:\n",
    "\n",
    "*   OpenAI API key (https://openai.com/)\n",
    "*   Serper API key (https://serper.dev/)\n",
    "*   Phoenix API key (https://app.phoenix.arize.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Prompt the user for their API keys if they haven't been set\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\", \"OPENAI_API_KEY\")\n",
    "serper_key = os.getenv(\"SERPER_API_KEY\", \"SERPER_API_KEY\")\n",
    "\n",
    "if openai_key == \"OPENAI_API_KEY\":\n",
    "    openai_key = getpass.getpass(\"Please enter your OPENAI_API_KEY: \")\n",
    "\n",
    "if serper_key == \"SERPER_API_KEY\":\n",
    "    serper_key = getpass.getpass(\"Please enter your SERPER_API_KEY: \")\n",
    "\n",
    "# Set the environment variables with the provided keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "os.environ[\"SERPER_API_KEY\"] = serper_key\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass.getpass(\"Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass.getpass(\"Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.environ['PHOENIX_API_KEY']}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9X87mdGnpbc"
   },
   "source": [
    "## Configure Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(project_name=\"crewai-agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYT-EU56ni94"
   },
   "source": [
    "# Instrument CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.crewai import CrewAIInstrumentor\n",
    "\n",
    "CrewAIInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "\n",
    "# Define worker agents\n",
    "trend_researcher = Agent(\n",
    "    role=\"AI Trend Researcher\",\n",
    "    goal=\"Analyze current advancements in AI\",\n",
    "    backstory=\"Expert in tracking and analyzing new trends in artificial intelligence.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "policy_analyst = Agent(\n",
    "    role=\"AI Policy Analyst\",\n",
    "    goal=\"Examine the implications of AI regulations and governance\",\n",
    "    backstory=\"Tracks AI policy developments across governments and organizations.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "risk_specialist = Agent(\n",
    "    role=\"AI Risk Specialist\",\n",
    "    goal=\"Identify potential risks in frontier AI development\",\n",
    "    backstory=\"Focuses on safety, alignment, and misuse risks related to advanced AI.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "synthesizer = Agent(\n",
    "    role=\"Synthesis Writer\",\n",
    "    goal=\"Summarize all findings into a final cohesive report\",\n",
    "    backstory=\"Expert at compiling research insights into executive-level narratives.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "orchestrator = Agent(\n",
    "    role=\"Orchestrator\",\n",
    "    goal=(\n",
    "        \"Your job is to delegate research and writing tasks to the correct coworker using the 'Delegate work to coworker' tool.\\n\"\n",
    "        \"For each task you assign, you MUST call the tool with the following JSON input:\\n\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"task\": \"Short summary of the task to do (plain string)\",\\n'\n",
    "        '  \"context\": \"Why this task is important or part of the report (plain string)\",\\n'\n",
    "        '  \"coworker\": \"One of: AI Trend Researcher, AI Policy Analyst, AI Risk Specialist, Synthesis Writer\"\\n'\n",
    "        \"}\\n\\n\"\n",
    "        \"IMPORTANT:\\n\"\n",
    "        \"- Do NOT format 'task' or 'context' as dictionaries.\\n\"\n",
    "        \"- Do NOT include types or nested descriptions.\\n\"\n",
    "        \"- Only use plain strings for both.\\n\"\n",
    "        \"- Call the tool multiple times, one per coworker.\"\n",
    "    ),\n",
    "    backstory=\"You are responsible for assigning each part of an AI report to the right specialist.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial task only for the orchestrator\n",
    "initial_task = Task(\n",
    "    description=\"Create an AI trends report. It should include recent innovations, policy updates, and safety risks. Then synthesize it into a unified summary.\",\n",
    "    expected_output=\"Assign subtasks via the DelegateWorkTool and return a final report.\",\n",
    "    agent=orchestrator,\n",
    ")\n",
    "\n",
    "# Set up the crew (no hierarchical process needed with delegation tools)\n",
    "crew = Crew(\n",
    "    agents=[trend_researcher, policy_analyst, risk_specialist, synthesizer],\n",
    "    tasks=[initial_task],\n",
    "    manager_agent=orchestrator,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Run the full workflow\n",
    "result = crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's add some Evaluations (Evals)\n",
    "\n",
    "In this section we will evaluate Agent Trajectory. \n",
    "\n",
    "See https://arize.com/docs/ax/evaluate/agent-trajectory-evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "df = px.Client().get_spans_dataframe(project_name=\"crewai-agents\", timeout=None)\n",
    "llm_spans = df[df[\"span_kind\"] == \"LLM\"]\n",
    "root_ids = df[df[\"parent_id\"].isna()][\"context.trace_id\"].unique()\n",
    "llm_spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE = \"\"\"\n",
    "You are a helpful AI bot that checks whether an AI agent's internal trajectory is accurate and effective.\n",
    "\n",
    "You will be given:\n",
    "1. The agent's actual trajectory of tool calls\n",
    "2. You will be given input data from a user that the agent used to make a decision\n",
    "3. You will be given a tool call definition, what the agent used to make the tool call\n",
    "\n",
    "An accurate trajectory:\n",
    "- Progresses logically from step to step\n",
    "- Follows the golden trajectory where reasonable\n",
    "- Shows a clear path toward completing a goal\n",
    "- Is reasonably efficient (doesn't take unnecessary detours)\n",
    "\n",
    "##\n",
    "\n",
    "Actual Trajectory:\n",
    "{tool_calls}\n",
    "\n",
    "Use Inputs:\n",
    "{attributes.input.value}\n",
    "\n",
    "Tool Definitions:\n",
    "{attributes.llm.tools}\n",
    "\n",
    "##\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the agent's trajectory adheres to the rubric and accomplishes the task effectively.\n",
    "- Respond with `incorrect` if the trajectory is confusing, misaligned with the goal, inefficient, or does not accomplish the task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_spans_by_trace_criteria(\n",
    "    df: pd.DataFrame,\n",
    "    trace_filters: Dict[str, Dict[str, Any]],\n",
    "    span_filters: Dict[str, Dict[str, Any]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filter spans based on trace-level and span-level criteria.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with trace data\n",
    "        trace_filters: Dictionary of column names and filtering criteria for traces\n",
    "                      Format: {\"column_name\": {\"operator\": value}}\n",
    "                      Supported operators: \">=\", \"<=\", \"==\", \"!=\", \"contains\", \"notna\", \"isna\"\n",
    "        span_filters: Dictionary of column names and filtering criteria for spans\n",
    "                     Format: {\"column_name\": {\"operator\": value}}\n",
    "                     Same supported operators as trace_filters\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with filtered spans from traces that match trace_filters\n",
    "    \"\"\"\n",
    "    all_trace_ids = set(df[\"context.trace_id\"].unique())\n",
    "    print(f\"Total traces: {len(all_trace_ids)}\")\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    traces_df = df_copy.copy()\n",
    "    for column, criteria in trace_filters.items():\n",
    "        if column not in traces_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                matching_spans = traces_df[traces_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                matching_spans = traces_df[traces_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                matching_spans = traces_df[traces_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                matching_spans = traces_df[traces_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                matching_spans = traces_df[\n",
    "                    traces_df[column].str.contains(value, case=False, na=False)\n",
    "                ]\n",
    "            elif operator == \"isna\":\n",
    "                matching_spans = traces_df[traces_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                matching_spans = traces_df[traces_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "            traces_df = matching_spans\n",
    "\n",
    "    matching_trace_ids = set(traces_df[\"context.trace_id\"].unique())\n",
    "    print(f\"Found {len(matching_trace_ids)} traces matching trace criteria\")\n",
    "\n",
    "    if not matching_trace_ids:\n",
    "        print(\"No matching traces found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    result_df = df[df[\"context.trace_id\"].isin(matching_trace_ids)].copy()\n",
    "\n",
    "    for column, criteria in span_filters.items():\n",
    "        if column not in result_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                result_df = result_df[result_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                result_df = result_df[result_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                result_df = result_df[result_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                result_df = result_df[result_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                result_df = result_df[result_df[column].str.contains(value, case=False, na=False)]\n",
    "            elif operator == \"isna\":\n",
    "                result_df = result_df[result_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                result_df = result_df[result_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Final result: {len(result_df)} spans from {len(matching_trace_ids)} traces\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def extract_tool_calls(output_messages):\n",
    "    if not output_messages:\n",
    "        return []\n",
    "\n",
    "    tool_calls = []\n",
    "    for message in output_messages:\n",
    "        if \"message.tool_calls\" in message:\n",
    "            for tool_call in message[\"message.tool_calls\"]:\n",
    "                tool_calls.append({\"name\": tool_call[\"tool_call.function.name\"]})\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "eval_traces = filter_spans_by_trace_criteria(\n",
    "    df=df,\n",
    "    trace_filters={\"name\": {\"contains\": \"agent\"}},\n",
    "    span_filters={\"attributes.openinference.span.kind\": {\"==\": \"LLM\"}},\n",
    ")\n",
    "\n",
    "eval_traces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_traces[\"tool_calls\"] = eval_traces[\"attributes.llm.output_messages\"].apply(extract_tool_calls)\n",
    "eval_traces.head()\n",
    "full_eval_spans = eval_traces[eval_traces[\"attributes.llm.tools\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from phoenix.evals import OpenAIModel, llm_classify\n",
    "from phoenix.trace import suppress_tracing\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = [\"correct\", \"incorrect\"]\n",
    "\n",
    "with suppress_tracing():\n",
    "    eval_results = llm_classify(\n",
    "        dataframe=full_eval_spans,\n",
    "        template=TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        verbose=False,\n",
    "        concurrency=20,\n",
    "    )\n",
    "\n",
    "eval_results[\"score\"] = eval_results[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.merge(full_eval_spans, eval_results, left_index=True, right_index=True)\n",
    "\n",
    "merged_df.rename(columns={\"context.trace_id\": \"context.span_id\"}, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(\n",
    "        dataframe=merged_df,\n",
    "        eval_name=\"Agent Trajectory Accuracy\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH0uVMgxpLql"
   },
   "source": [
    "### Check your Phoenix project to view the traces and spans from your runs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
