{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUknhuHKyc-E"
   },
   "source": [
    "# <center>OpenAI agent pattern: orchestrator and workers</center>\n",
    "\n",
    "A starter guide for building an agent loop using the `openai-agents` library.\n",
    "\n",
    "This pattern uses orchestators and workers. The orchestrator chooses which worker to use for a specific sub-task. The worker attempts to complete the sub-task and return a result. The orchestrator then uses the result to choose the next worker to use until a final result is returned.\n",
    "\n",
    "In the following example, we'll build an agent which creates a portfolio of stocks and ETFs based on a user's investment strategy.\n",
    "1.  **Orchestrator:** Chooses which worker to use based on the user's investment strategy.\n",
    "2.  **Research Agent:** Searches the web for information about stocks and ETFs that could support the user's investment strategy.\n",
    "3.  **Evaluation Agent:** Evaluates the research report and provides feedback on what data is missing.\n",
    "4.  **Portfolio Agent:** Creates a portfolio of stocks and ETFs based on the research report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n69HR7eJswNt"
   },
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install base libraries for OpenAI\n",
    "%pip install -q openai openai-agents\n",
    "\n",
    "# Install optional libraries for OpenInference/OpenTelemetry tracing\n",
    "%pip install -q arize-phoenix-otel arize-phoenix-evals openinference-instrumentation-openai-agents openinference-instrumentation-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQnyEnJisyn3"
   },
   "source": [
    "### Setup Keys\n",
    "\n",
    "Add your OpenAI API key to the environment variable `OPENAI_API_KEY`.\n",
    "\n",
    "Copy your Phoenix `API_KEY` from your settings page at [app.phoenix.arize.com](https://app.phoenix.arize.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import phoenix as px\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"ðŸ”‘ Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_COLLECTOR_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = getpass(\"ðŸ”‘ Enter your Phoenix Collector Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfid5cE99yN5"
   },
   "source": [
    "### Setup Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=\"Orchestrator-workers\", protocol=\"http/protobuf\", auto_instrument=True, batch=True\n",
    ")\n",
    "\n",
    "tracer = trace.get_tracer(\"Orchestrator-workers\")\n",
    "\n",
    "client = px.Client()\n",
    "PROJECT = \"Orchestrator-workers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, Runner, TResponseInputItem, WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class PortfolioItem(BaseModel):\n",
    "    ticker: str = Field(description=\"The ticker of the stock or ETF.\")\n",
    "    allocation: float = Field(\n",
    "        description=\"The percentage allocation of the ticker in the portfolio. The sum of all allocations should be 100.\"\n",
    "    )\n",
    "    reason: str = Field(description=\"The reason why this ticker is included in the portfolio.\")\n",
    "\n",
    "\n",
    "class Portfolio(BaseModel):\n",
    "    tickers: list[PortfolioItem] = Field(\n",
    "        description=\"A list of tickers that could support the user's stated investment strategy.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EvaluationFeedback(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"What data is missing in order to create a portfolio of stocks and ETFs based on the user's investment strategy.\"\n",
    "    )\n",
    "    score: Literal[\"pass\", \"needs_improvement\", \"fail\"] = Field(\n",
    "        description=\"A score on the research report. Pass if you have at least 5 tickers with data that supports the user's investment strategy to create a portfolio, needs_improvement if you do not have enough supporting data, and fail if you have no tickers.\"\n",
    "    )\n",
    "\n",
    "\n",
    "evaluation_agent = Agent(\n",
    "    name=\"Evaluation Agent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a senior financial analyst. You will be provided with a stock research report with positive and negative catalysts. Your task is to evaluate the report and provide feedback on what to improve.\"\"\"\n",
    "    ),\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=EvaluationFeedback,\n",
    ")\n",
    "\n",
    "portfolio_agent = Agent(\n",
    "    name=\"Portfolio Agent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a senior financial analyst. You will be provided with a stock research report. Your task is to create a portfolio of stocks and ETFs that could support the user's stated investment strategy. Include facts and data from the research report in the stated reasons for the portfolio allocation.\"\"\"\n",
    "    ),\n",
    "    model=\"o4-mini\",\n",
    "    output_type=Portfolio,\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"FinancialSearchAgent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a research assistant specializing in financial topics. Given a stock ticker, use web search to retrieve upâ€‘toâ€‘date context and produce a short summary of at most 50 words. Focus on key numbers, events, or quotes that will be useful to a financial analyst.\"\"\"\n",
    "    ),\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\", parallel_tool_calls=True),\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"Routing Agent\",\n",
    "    instructions=dedent(\"\"\"You are a senior financial analyst. You are trying to create a portfolio based on my stated investment strategy. Your task is to handoff to the appropriate agent or tool.\n",
    "\n",
    "    First, handoff to the research_agent to give you a report on stocks and ETFs that could support the user's stated investment strategy.\n",
    "    Then, handoff to the evaluation_agent to give you a score on the research report. If the evaluation_agent returns a needs_improvement or fail, continue using the research_agent to gather more information.\n",
    "    Once the evaluation_agent returns a pass, handoff to the portfolio_agent to create a portfolio.\"\"\"),\n",
    "    model=\"gpt-4.1\",\n",
    "    handoffs=[\n",
    "        research_agent,\n",
    "        evaluation_agent,\n",
    "        portfolio_agent,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our Workflow! \n",
    "\n",
    "Enter your investment strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from uuid import uuid4\n",
    "\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "\n",
    "MAX_PASSES = 10\n",
    "PASS_TIMEOUT = 500\n",
    "\n",
    "\n",
    "async def run_agent_workflow():\n",
    "    user_input = input(\"Enter your investment strategy: \")\n",
    "    input_items: list[TResponseInputItem] = [{\"content\": user_input, \"role\": \"user\"}]\n",
    "\n",
    "    with tracer.start_as_current_span(\n",
    "        \"Agent workflow\",\n",
    "        attributes={\n",
    "            SpanAttributes.OPENINFERENCE_SPAN_KIND: \"agent\",\n",
    "            SpanAttributes.INPUT_VALUE: user_input,\n",
    "            SpanAttributes.SESSION_ID: str(uuid4()),\n",
    "        },\n",
    "    ) as root_span:\n",
    "        passes = 0\n",
    "        while passes < MAX_PASSES:\n",
    "            try:\n",
    "                orchestrator = await asyncio.wait_for(\n",
    "                    Runner.run(orchestrator_agent, input_items),\n",
    "                    timeout=PASS_TIMEOUT,\n",
    "                )\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Pass {passes + 1} hit the {PASS_TIMEOUT}s timeoutâ€”aborting.\")\n",
    "                break\n",
    "\n",
    "            out = orchestrator.final_output\n",
    "            pprint(out)\n",
    "\n",
    "            if isinstance(out, Portfolio):\n",
    "                break\n",
    "\n",
    "            input_items = orchestrator.to_input_list()\n",
    "            passes += 1\n",
    "\n",
    "        root_span.set_attribute(SpanAttributes.OUTPUT_VALUE, str(out))\n",
    "\n",
    "    print(\"AGENT COMPLETE\")\n",
    "\n",
    "\n",
    "await run_agent_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = client.get_spans_dataframe(project_name=\"Orchestrator-workers\", timeout=None)\n",
    "llm_spans = df[df[\"span_kind\"] == \"LLM\"]\n",
    "root_ids = df[df[\"parent_id\"].isna()][\"context.trace_id\"].unique()\n",
    "llm_spans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE = \"\"\"\n",
    "You are a helpful AI bot that checks whether an AI agent's internal trajectory is accurate and effective.\n",
    "\n",
    "You will be given:\n",
    "1. The agent's actual trajectory of tool calls\n",
    "2. You will be given input data from a user that the agent used to make a decision\n",
    "3. You will be given a tool call definition, what the agent used to make the tool call\n",
    "\n",
    "An accurate trajectory:\n",
    "- Progresses logically from step to step\n",
    "- Follows the golden trajectory where reasonable\n",
    "- Shows a clear path toward completing a goal\n",
    "- Is reasonably efficient (doesn't take unnecessary detours)\n",
    "\n",
    "##\n",
    "\n",
    "Actual Trajectory:\n",
    "{tool_calls}\n",
    "\n",
    "Use Inputs:\n",
    "{attributes.input.value}\n",
    "\n",
    "Tool Definitions:\n",
    "{attributes.llm.tools}\n",
    "\n",
    "##\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the agent's trajectory adheres to the rubric and accomplishes the task effectively.\n",
    "- Respond with `incorrect` if the trajectory is confusing, misaligned with the goal, inefficient, or does not accomplish the task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_spans_by_trace_criteria(\n",
    "    df: pd.DataFrame,\n",
    "    trace_filters: Dict[str, Dict[str, Any]],\n",
    "    span_filters: Dict[str, Dict[str, Any]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Filter spans based on trace-level and span-level criteria.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with trace data\n",
    "        trace_filters: Dictionary of column names and filtering criteria for traces\n",
    "                      Format: {\"column_name\": {\"operator\": value}}\n",
    "                      Supported operators: \">=\", \"<=\", \"==\", \"!=\", \"contains\", \"notna\", \"isna\"\n",
    "        span_filters: Dictionary of column names and filtering criteria for spans\n",
    "                     Format: {\"column_name\": {\"operator\": value}}\n",
    "                     Same supported operators as trace_filters\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with filtered spans from traces that match trace_filters\n",
    "    \"\"\"\n",
    "    all_trace_ids = set(df[\"context.trace_id\"].unique())\n",
    "    print(f\"Total traces: {len(all_trace_ids)}\")\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    traces_df = df_copy.copy()\n",
    "    for column, criteria in trace_filters.items():\n",
    "        if column not in traces_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                matching_spans = traces_df[traces_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                matching_spans = traces_df[traces_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                matching_spans = traces_df[traces_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                matching_spans = traces_df[traces_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                matching_spans = traces_df[\n",
    "                    traces_df[column].str.contains(value, case=False, na=False)\n",
    "                ]\n",
    "            elif operator == \"isna\":\n",
    "                matching_spans = traces_df[traces_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                matching_spans = traces_df[traces_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "            traces_df = matching_spans\n",
    "\n",
    "    matching_trace_ids = set(traces_df[\"context.trace_id\"].unique())\n",
    "    print(f\"Found {len(matching_trace_ids)} traces matching trace criteria\")\n",
    "\n",
    "    if not matching_trace_ids:\n",
    "        print(\"No matching traces found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    result_df = df[df[\"context.trace_id\"].isin(matching_trace_ids)].copy()\n",
    "\n",
    "    for column, criteria in span_filters.items():\n",
    "        if column not in result_df.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in dataframe\")\n",
    "            continue\n",
    "\n",
    "        for operator, value in criteria.items():\n",
    "            if operator == \">=\":\n",
    "                result_df = result_df[result_df[column] >= value]\n",
    "            elif operator == \"<=\":\n",
    "                result_df = result_df[result_df[column] <= value]\n",
    "            elif operator == \"==\":\n",
    "                result_df = result_df[result_df[column] == value]\n",
    "            elif operator == \"!=\":\n",
    "                result_df = result_df[result_df[column] != value]\n",
    "            elif operator == \"contains\":\n",
    "                result_df = result_df[result_df[column].str.contains(value, case=False, na=False)]\n",
    "            elif operator == \"isna\":\n",
    "                result_df = result_df[result_df[column].isna()]\n",
    "            elif operator == \"notna\":\n",
    "                result_df = result_df[result_df[column].notna()]\n",
    "            else:\n",
    "                print(f\"Warning: Unsupported operator '{operator}' - skipping\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Final result: {len(result_df)} spans from {len(matching_trace_ids)} traces\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def extract_tool_calls(output_messages):\n",
    "    if not output_messages:\n",
    "        return []\n",
    "\n",
    "    tool_calls = []\n",
    "    for message in output_messages:\n",
    "        if \"message.tool_calls\" in message:\n",
    "            for tool_call in message[\"message.tool_calls\"]:\n",
    "                tool_calls.append({\"name\": tool_call[\"tool_call.function.name\"]})\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "eval_traces = filter_spans_by_trace_criteria(\n",
    "    df=df,\n",
    "    trace_filters={\"name\": {\"contains\": \"agent\"}},\n",
    "    span_filters={\"attributes.openinference.span.kind\": {\"==\": \"LLM\"}},\n",
    ")\n",
    "\n",
    "eval_traces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_traces[\"tool_calls\"] = eval_traces[\"attributes.llm.output_messages\"].apply(extract_tool_calls)\n",
    "eval_traces.head()\n",
    "full_eval_spans = eval_traces[eval_traces[\"attributes.llm.tools\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from phoenix.evals import OpenAIModel, llm_classify\n",
    "from phoenix.trace import suppress_tracing\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = [\"correct\", \"incorrect\"]\n",
    "\n",
    "with suppress_tracing():\n",
    "    eval_results = llm_classify(\n",
    "        dataframe=full_eval_spans,\n",
    "        template=TRAJECTORY_ACCURACY_PROMPT_WITHOUT_REFERENCE,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        verbose=False,\n",
    "        concurrency=20,\n",
    "    )\n",
    "\n",
    "eval_results[\"score\"] = eval_results[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.merge(full_eval_spans, eval_results, left_index=True, right_index=True)\n",
    "\n",
    "merged_df.rename(columns={\"context.trace_id\": \"context.span_id\"}, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "client.log_evaluations(\n",
    "    SpanEvaluations(\n",
    "        dataframe=merged_df,\n",
    "        eval_name=\"Agent Trajectory Accuracy\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
