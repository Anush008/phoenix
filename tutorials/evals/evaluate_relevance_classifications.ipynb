{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<center>\n",
                "    <p style=\"text-align:center\">\n",
                "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
                "        <br>\n",
                "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
                "        |\n",
                "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
                "        |\n",
                "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
                "    </p>\n",
                "</center>\n",
                "<h1 align=\"center\">Retrieval Relevance Evals</h1>\n",
                "\n",
                "Arize provides tooling to evaluate LLM applications, including tools to determine the relevance or irrelevance of documents retrieved by retrieval-augmented generation (RAG) applications. This relevance is then used to measure the quality of each retrieval using ranking metrics such as precision@k. In order to determine whether each retrieved document is relevant or irrelevant to the corresponding query, our approach is straightforward: ask an LLM.\n",
                "\n",
                "The purpose of this notebook is:\n",
                "\n",
                "- to evaluate the performance of an LLM-assisted approach to relevance classification against information retrieval datasets with ground-truth relevance labels,\n",
                "- to provide an experimental framework for users to iterate and improve on the default classification template.\n",
                "\n",
                "## Install Dependencies and Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#####################\n",
                "## N_EVAL_SAMPLE_SIZE\n",
                "#####################\n",
                "# Eval sample size determines the run time\n",
                "# 100 samples: GPT-4 ~ 80 sec / GPT-3.5 ~ 40 sec\n",
                "# 1,000 samples: GPT-4 ~15-17 min / GPT-3.5 ~ 6-7min (depending on retries)\n",
                "# 10,000 samples GPT-4 ~170 min / GPT-3.5 ~ 70min\n",
                "N_EVAL_SAMPLE_SIZE = 500"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -qq \"arize-phoenix-evals>=0.0.5\" \"openai>=1\" ipython matplotlib pycm scikit-learn tiktoken nest_asyncio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ℹ️ To enable async request submission in notebook environments like Jupyter or Google Colab, optionally use `nest_asyncio`. `nest_asyncio` globally patches `asyncio` to enable event loops to be re-entrant. This is not required for non-notebook environments.\n",
                "\n",
                "Without `nest_asyncio`, eval submission can be much slower, depending on your organization's rate limits. Speed increases of about 5x are typical."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nest_asyncio\n",
                "\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from getpass import getpass\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from phoenix.evals import (\n",
                "    RAG_RELEVANCY_PROMPT_RAILS_MAP,\n",
                "    RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
                "    OpenAIModel,\n",
                "    download_benchmark_dataset,\n",
                "    llm_classify,\n",
                ")\n",
                "from pycm import ConfusionMatrix\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "pd.set_option(\"display.max_colwidth\", None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download Benchmark Dataset\n",
                "\n",
                "We'll evaluate the evaluation system consisting of an LLM model and settings in addition to an evaluation prompt template against benchmark datasets of queries and retrieved documents with ground-truth relevance labels. Currently supported datasets include:\n",
                "\n",
                "- \"wiki_qa-train\"\n",
                "- \"ms_marco-v1.1-train\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>query_id</th>\n",
                            "      <th>query_text</th>\n",
                            "      <th>document_title</th>\n",
                            "      <th>document_text</th>\n",
                            "      <th>document_text_with_emphasis</th>\n",
                            "      <th>relevant</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Q0</td>\n",
                            "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
                            "      <td>African immigration to the United States</td>\n",
                            "      <td>African immigration to the United States refers to immigrants to the United States who are or were nationals of Africa . The term African in the scope of this article refers to geographical or national origins rather than racial affiliation. From the Immigration and Nationality Act of 1965 to 2007, an estimated total of 0.8 to 0.9 million Africans immigrated to the United States, accounting for roughly 3.3% of total immigration to the United States during this period. African immigrants in the United States come from almost all regions in Africa and do not constitute a homogeneous group. They include people from different national, linguistic, ethnic, racial, cultural and social backgrounds. As such, African immigrants are to be distinguished from African American people, the latter of whom are descendants of mostly West and Central Africans who were involuntarily brought to the United States by means of the historic Atlantic slave trade .</td>\n",
                            "      <td>African immigration to the United States refers to immigrants to the United States who are or were nationals of Africa . The term African in the scope of this article refers to geographical or national origins rather than racial affiliation. From the Immigration and Nationality Act of 1965 to 2007, an estimated total of 0.8 to 0.9 million Africans immigrated to the United States, accounting for roughly 3.3% of total immigration to the United States during this period. African immigrants in the United States come from almost all regions in Africa and do not constitute a homogeneous group. They include people from different national, linguistic, ethnic, racial, cultural and social backgrounds. AS SUCH, AFRICAN IMMIGRANTS ARE TO BE DISTINGUISHED FROM AFRICAN AMERICAN PEOPLE, THE LATTER OF WHOM ARE DESCENDANTS OF MOSTLY WEST AND CENTRAL AFRICANS WHO WERE INVOLUNTARILY BROUGHT TO THE UNITED STATES BY MEANS OF THE HISTORIC ATLANTIC SLAVE TRADE .</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Q1012</td>\n",
                            "      <td>what are points on a mortgage</td>\n",
                            "      <td>Point (mortgage)</td>\n",
                            "      <td>Points, sometimes also called a \"discount point\", are a form of pre-paid interest . One point equals one percent of the loan amount. By charging a borrower points, a lender effectively increases the yield on the loan above the amount of the stated interest rate . Borrowers can offer to pay a lender points as a method to reduce the interest rate on the loan, thus obtaining a lower monthly payment in exchange for this up-front payment. For each point purchased, the loan rate is typically reduced by 1/8% (0.125%). Paying Points represent a calculated gamble on the part of the buyer. There will be a specific point in the timeline of the loan where the money spent to buy down the interest rate will be equal to the money saved by making reduced loan payments resulting from the lower interest rate on the loan. Selling the property or refinancing prior to this break-even point will result in a net financial loss for the buyer while keeping the loan for longer than this break-even point will result in a net financial savings for the buyer. The longer you keep the property financed under the loan with purchased points, the more the money spent on the points will pay off. Accordingly, if the intention is to buy and sell the property or refinance in a rapid fashion, buying points is actually going to end up costing more than just paying the loan at the higher interest rate. Points may also be purchased to reduce the monthly payment for the purpose of qualifying for a loan. Loan qualification based on monthly income versus the monthly loan payment may sometimes only be achievable by reducing the monthly payment through the purchasing of points to buy down the interest rate, thereby reducing the monthly loan payment. Discount points may be different from origination fee or broker fee . Discount points are always used to buy down the interest rates, while origination fees sometimes are fees the lender charges for the loan or sometimes just another name for buying down the interest rate. Origination fee and discount points are both items listed under lender-charges on the HUD-1 Settlement Statement . The difference in savings over the life of the loan can make paying points a benefit to the borrower. If you intend to stay in your home for an extended period of time, it may be worthwhile to pay additional points in order to obtain a lower interest rate. Any significant changes in fees should be re-disclosed in the final good faith estimate (GFE). Also directly related to points is the concept of the ' no closing cost loan '. If points are paid to acquire a loan, it is impossible at the same time for a broker bank or lender to make a premium for a higher rate. When premium is earned by making the note rate higher, this premium is sometimes used to pay the closing costs.</td>\n",
                            "      <td>POINTS, SOMETIMES ALSO CALLED A \"DISCOUNT POINT\", ARE A FORM OF PRE-PAID INTEREST . One point equals one percent of the loan amount. By charging a borrower points, a lender effectively increases the yield on the loan above the amount of the stated interest rate . Borrowers can offer to pay a lender points as a method to reduce the interest rate on the loan, thus obtaining a lower monthly payment in exchange for this up-front payment. For each point purchased, the loan rate is typically reduced by 1/8% (0.125%). Paying Points represent a calculated gamble on the part of the buyer. There will be a specific point in the timeline of the loan where the money spent to buy down the interest rate will be equal to the money saved by making reduced loan payments resulting from the lower interest rate on the loan. Selling the property or refinancing prior to this break-even point will result in a net financial loss for the buyer while keeping the loan for longer than this break-even point will result in a net financial savings for the buyer. The longer you keep the property financed under the loan with purchased points, the more the money spent on the points will pay off. Accordingly, if the intention is to buy and sell the property or refinance in a rapid fashion, buying points is actually going to end up costing more than just paying the loan at the higher interest rate. Points may also be purchased to reduce the monthly payment for the purpose of qualifying for a loan. Loan qualification based on monthly income versus the monthly loan payment may sometimes only be achievable by reducing the monthly payment through the purchasing of points to buy down the interest rate, thereby reducing the monthly loan payment. Discount points may be different from origination fee or broker fee . Discount points are always used to buy down the interest rates, while origination fees sometimes are fees the lender charges for the loan or sometimes just another name for buying down the interest rate. Origination fee and discount points are both items listed under lender-charges on the HUD-1 Settlement Statement . The difference in savings over the life of the loan can make paying points a benefit to the borrower. If you intend to stay in your home for an extended period of time, it may be worthwhile to pay additional points in order to obtain a lower interest rate. Any significant changes in fees should be re-disclosed in the final good faith estimate (GFE). Also directly related to points is the concept of the ' no closing cost loan '. If points are paid to acquire a loan, it is impossible at the same time for a broker bank or lender to make a premium for a higher rate. When premium is earned by making the note rate higher, this premium is sometimes used to pay the closing costs.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Q1018</td>\n",
                            "      <td>when did 311 make Amber</td>\n",
                            "      <td>311 (band)</td>\n",
                            "      <td>311 (pronounced \"three-eleven\") is an American rock band from Omaha , Nebraska . The band was formed in 1988 by vocalist/guitarist Nick Hexum , lead guitarist Jim Watson (who would later be replaced by Tim Mahoney), bassist Aaron \"P-Nut\" Wills and drummer Chad Sexton. In 1992, Doug \"SA\" Martinez joined to sing and provide turntables for 311's later albums, rounding out the current line-up. 311 is generally known as an alternative rock band, but it is also classified as rap rock , rap metal , funk rock , funk metal , reggae and jazz fusion . The band's name originates from the police code for indecent exposure in Omaha, Nebraska, after the original guitarist for the band was arrested for streaking . After a series of independent releases, 311 was signed to Capricorn Records in 1992 and released the albums Music (1993) and Grassroots (1994) to moderate success. They achieved greater success with their 1995 triple platinum self-titled album , which reached No. 12 on the Billboard 200 on the strength of the singles \" Down \" and \" All Mixed Up \", the former of which topped the Billboard Hot Modern Rock Tracks in 1996. The band's next three albums, Transistor (1997), Soundsystem (1999) and From Chaos (2001), did not achieve the massive success of the self-titled album, though they were still successful, with the first going platinum and the last two going gold. Their 2004 compilation album Greatest Hits '93–'03 was also certified gold. The band's most recent studio album is 2011's Universal Pulse . To date, 311 has released ten studio albums, one live album, four compilation albums, four EPs and four DVDs. As of 2011, 311 has sold over 8.5 million records in the US. They are currently working on a new album, which is due for release in 2013.</td>\n",
                            "      <td>311 (pronounced \"three-eleven\") is an American rock band from Omaha , Nebraska . The band was formed in 1988 by vocalist/guitarist Nick Hexum , lead guitarist Jim Watson (who would later be replaced by Tim Mahoney), bassist Aaron \"P-Nut\" Wills and drummer Chad Sexton. In 1992, Doug \"SA\" Martinez joined to sing and provide turntables for 311's later albums, rounding out the current line-up. 311 is generally known as an alternative rock band, but it is also classified as rap rock , rap metal , funk rock , funk metal , reggae and jazz fusion . The band's name originates from the police code for indecent exposure in Omaha, Nebraska, after the original guitarist for the band was arrested for streaking . After a series of independent releases, 311 was signed to Capricorn Records in 1992 and released the albums Music (1993) and Grassroots (1994) to moderate success. They achieved greater success with their 1995 triple platinum self-titled album , which reached No. 12 on the Billboard 200 on the strength of the singles \" Down \" and \" All Mixed Up \", the former of which topped the Billboard Hot Modern Rock Tracks in 1996. The band's next three albums, Transistor (1997), Soundsystem (1999) and From Chaos (2001), did not achieve the massive success of the self-titled album, though they were still successful, with the first going platinum and the last two going gold. Their 2004 compilation album Greatest Hits '93–'03 was also certified gold. The band's most recent studio album is 2011's Universal Pulse . To date, 311 has released ten studio albums, one live album, four compilation albums, four EPs and four DVDs. As of 2011, 311 has sold over 8.5 million records in the US. They are currently working on a new album, which is due for release in 2013.</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Q102</td>\n",
                            "      <td>how does interlibrary loan work</td>\n",
                            "      <td>Interlibrary loan</td>\n",
                            "      <td>Interlibrary loan (abbreviated ILL, and sometimes called interloan, document delivery, or document supply) is a service whereby a user of one library can borrow books or receive photocopies of documents that are owned by another library. The user makes a request with their local library, which, acting as an intermediary, identifies owners of the desired item, places the request, receives the item, makes it available to the user, and arranges for its return. The lending library usually sets the due date and overdue fees of the material borrowed. Although books and journal articles are the most frequently requested items, some libraries will lend audio recordings, video recordings, maps, sheet music, and microforms of all kinds. In many cases, nominal fees accompany interlibrary loan services. The term document delivery may also be used for a related service, namely the supply of journal articles and other copies on a personalized basis, whether these come from other libraries or direct from publishers. The end user is usually responsible for any fees, such as costs for postage or photocopying. Commercial document delivery services will borrow on behalf of any customer willing to pay their rates.</td>\n",
                            "      <td>INTERLIBRARY LOAN (ABBREVIATED ILL, AND SOMETIMES CALLED INTERLOAN, DOCUMENT DELIVERY, OR DOCUMENT SUPPLY) IS A SERVICE WHEREBY A USER OF ONE LIBRARY CAN BORROW BOOKS OR RECEIVE PHOTOCOPIES OF DOCUMENTS THAT ARE OWNED BY ANOTHER LIBRARY. THE USER MAKES A REQUEST WITH THEIR LOCAL LIBRARY, WHICH, ACTING AS AN INTERMEDIARY, IDENTIFIES OWNERS OF THE DESIRED ITEM, PLACES THE REQUEST, RECEIVES THE ITEM, MAKES IT AVAILABLE TO THE USER, AND ARRANGES FOR ITS RETURN. The lending library usually sets the due date and overdue fees of the material borrowed. Although books and journal articles are the most frequently requested items, some libraries will lend audio recordings, video recordings, maps, sheet music, and microforms of all kinds. In many cases, nominal fees accompany interlibrary loan services. The term document delivery may also be used for a related service, namely the supply of journal articles and other copies on a personalized basis, whether these come from other libraries or direct from publishers. The end user is usually responsible for any fees, such as costs for postage or photocopying. Commercial document delivery services will borrow on behalf of any customer willing to pay their rates.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Q1021</td>\n",
                            "      <td>who did cy young play for</td>\n",
                            "      <td>Cy Young</td>\n",
                            "      <td>Denton True \"Cy\" Young (March 29, 1867 – November 4, 1955) was an American Major League Baseball pitcher . During his 22-year baseball career (1890–1911), he pitched for five different teams. Young established numerous pitching records, some of which have stood for a century. Young compiled 511 wins , which is most in Major League history and 94 ahead of Walter Johnson who is second on the list. Young was elected to the National Baseball Hall of Fame in 1937. One year after Young's death, the Cy Young Award was created to honor the previous season's best pitcher. In addition to wins, Young still holds the major league records for most career innings pitched (7,355), most career games started (815), and most complete games (749). He also retired with 316 losses , the most in MLB history. Young's 76 career shutouts are fourth all-time. He also won at least 30 games in a season five times, with ten other seasons of 20 or more wins. In addition, Young pitched three no-hitters , including the third perfect game in baseball history, first in baseball's \"modern era\". In 1999, 88 years after his final major league appearance and 44 years after his death, editors at The Sporting News ranked Cy Young 14th on their list of \"Baseball's 100 Greatest Players\". That same year, baseball fans named him to the Major League Baseball All-Century Team . Young's career started in 1890 with the Cleveland Spiders . After eight years with the Spiders, Young was moved to St. Louis in 1899. After two years there, Young jumped to the newly-created American League , joining the Boston franchise. He was traded back to Cleveland in 1909, before spending the final two months of his career with the Boston Rustlers . After his retirement, Young went back to his farm in Ohio , where he stayed until his death at age 88 in 1955.</td>\n",
                            "      <td>Denton True \"Cy\" Young (March 29, 1867 – November 4, 1955) was an American Major League Baseball pitcher . During his 22-year baseball career (1890–1911), he pitched for five different teams. Young established numerous pitching records, some of which have stood for a century. Young compiled 511 wins , which is most in Major League history and 94 ahead of Walter Johnson who is second on the list. Young was elected to the National Baseball Hall of Fame in 1937. One year after Young's death, the Cy Young Award was created to honor the previous season's best pitcher. In addition to wins, Young still holds the major league records for most career innings pitched (7,355), most career games started (815), and most complete games (749). He also retired with 316 losses , the most in MLB history. Young's 76 career shutouts are fourth all-time. He also won at least 30 games in a season five times, with ten other seasons of 20 or more wins. In addition, Young pitched three no-hitters , including the third perfect game in baseball history, first in baseball's \"modern era\". In 1999, 88 years after his final major league appearance and 44 years after his death, editors at The Sporting News ranked Cy Young 14th on their list of \"Baseball's 100 Greatest Players\". That same year, baseball fans named him to the Major League Baseball All-Century Team . Young's career started in 1890 with the Cleveland Spiders . After eight years with the Spiders, Young was moved to St. Louis in 1899. After two years there, Young jumped to the newly-created American League , joining the Boston franchise. He was traded back to Cleveland in 1909, before spending the final two months of his career with the Boston Rustlers . After his retirement, Young went back to his farm in Ohio , where he stayed until his death at age 88 in 1955.</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  query_id                                       query_text  \\\n",
                            "0       Q0  HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
                            "1    Q1012                    what are points on a mortgage   \n",
                            "2    Q1018                          when did 311 make Amber   \n",
                            "3     Q102                  how does interlibrary loan work   \n",
                            "4    Q1021                        who did cy young play for   \n",
                            "\n",
                            "                             document_title  \\\n",
                            "0  African immigration to the United States   \n",
                            "1                          Point (mortgage)   \n",
                            "2                                311 (band)   \n",
                            "3                         Interlibrary loan   \n",
                            "4                                  Cy Young   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        document_text  \\\n",
                            "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           African immigration to the United States refers to immigrants to the United States who are or were nationals of Africa . The term African in the scope of this article refers to geographical or national origins rather than racial affiliation. From the Immigration and Nationality Act of 1965 to 2007, an estimated total of 0.8 to 0.9 million Africans immigrated to the United States, accounting for roughly 3.3% of total immigration to the United States during this period. African immigrants in the United States come from almost all regions in Africa and do not constitute a homogeneous group. They include people from different national, linguistic, ethnic, racial, cultural and social backgrounds. As such, African immigrants are to be distinguished from African American people, the latter of whom are descendants of mostly West and Central Africans who were involuntarily brought to the United States by means of the historic Atlantic slave trade .   \n",
                            "1  Points, sometimes also called a \"discount point\", are a form of pre-paid interest . One point equals one percent of the loan amount. By charging a borrower points, a lender effectively increases the yield on the loan above the amount of the stated interest rate . Borrowers can offer to pay a lender points as a method to reduce the interest rate on the loan, thus obtaining a lower monthly payment in exchange for this up-front payment. For each point purchased, the loan rate is typically reduced by 1/8% (0.125%). Paying Points represent a calculated gamble on the part of the buyer. There will be a specific point in the timeline of the loan where the money spent to buy down the interest rate will be equal to the money saved by making reduced loan payments resulting from the lower interest rate on the loan. Selling the property or refinancing prior to this break-even point will result in a net financial loss for the buyer while keeping the loan for longer than this break-even point will result in a net financial savings for the buyer. The longer you keep the property financed under the loan with purchased points, the more the money spent on the points will pay off. Accordingly, if the intention is to buy and sell the property or refinance in a rapid fashion, buying points is actually going to end up costing more than just paying the loan at the higher interest rate. Points may also be purchased to reduce the monthly payment for the purpose of qualifying for a loan. Loan qualification based on monthly income versus the monthly loan payment may sometimes only be achievable by reducing the monthly payment through the purchasing of points to buy down the interest rate, thereby reducing the monthly loan payment. Discount points may be different from origination fee or broker fee . Discount points are always used to buy down the interest rates, while origination fees sometimes are fees the lender charges for the loan or sometimes just another name for buying down the interest rate. Origination fee and discount points are both items listed under lender-charges on the HUD-1 Settlement Statement . The difference in savings over the life of the loan can make paying points a benefit to the borrower. If you intend to stay in your home for an extended period of time, it may be worthwhile to pay additional points in order to obtain a lower interest rate. Any significant changes in fees should be re-disclosed in the final good faith estimate (GFE). Also directly related to points is the concept of the ' no closing cost loan '. If points are paid to acquire a loan, it is impossible at the same time for a broker bank or lender to make a premium for a higher rate. When premium is earned by making the note rate higher, this premium is sometimes used to pay the closing costs.   \n",
                            "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               311 (pronounced \"three-eleven\") is an American rock band from Omaha , Nebraska . The band was formed in 1988 by vocalist/guitarist Nick Hexum , lead guitarist Jim Watson (who would later be replaced by Tim Mahoney), bassist Aaron \"P-Nut\" Wills and drummer Chad Sexton. In 1992, Doug \"SA\" Martinez joined to sing and provide turntables for 311's later albums, rounding out the current line-up. 311 is generally known as an alternative rock band, but it is also classified as rap rock , rap metal , funk rock , funk metal , reggae and jazz fusion . The band's name originates from the police code for indecent exposure in Omaha, Nebraska, after the original guitarist for the band was arrested for streaking . After a series of independent releases, 311 was signed to Capricorn Records in 1992 and released the albums Music (1993) and Grassroots (1994) to moderate success. They achieved greater success with their 1995 triple platinum self-titled album , which reached No. 12 on the Billboard 200 on the strength of the singles \" Down \" and \" All Mixed Up \", the former of which topped the Billboard Hot Modern Rock Tracks in 1996. The band's next three albums, Transistor (1997), Soundsystem (1999) and From Chaos (2001), did not achieve the massive success of the self-titled album, though they were still successful, with the first going platinum and the last two going gold. Their 2004 compilation album Greatest Hits '93–'03 was also certified gold. The band's most recent studio album is 2011's Universal Pulse . To date, 311 has released ten studio albums, one live album, four compilation albums, four EPs and four DVDs. As of 2011, 311 has sold over 8.5 million records in the US. They are currently working on a new album, which is due for release in 2013.   \n",
                            "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Interlibrary loan (abbreviated ILL, and sometimes called interloan, document delivery, or document supply) is a service whereby a user of one library can borrow books or receive photocopies of documents that are owned by another library. The user makes a request with their local library, which, acting as an intermediary, identifies owners of the desired item, places the request, receives the item, makes it available to the user, and arranges for its return. The lending library usually sets the due date and overdue fees of the material borrowed. Although books and journal articles are the most frequently requested items, some libraries will lend audio recordings, video recordings, maps, sheet music, and microforms of all kinds. In many cases, nominal fees accompany interlibrary loan services. The term document delivery may also be used for a related service, namely the supply of journal articles and other copies on a personalized basis, whether these come from other libraries or direct from publishers. The end user is usually responsible for any fees, such as costs for postage or photocopying. Commercial document delivery services will borrow on behalf of any customer willing to pay their rates.   \n",
                            "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Denton True \"Cy\" Young (March 29, 1867 – November 4, 1955) was an American Major League Baseball pitcher . During his 22-year baseball career (1890–1911), he pitched for five different teams. Young established numerous pitching records, some of which have stood for a century. Young compiled 511 wins , which is most in Major League history and 94 ahead of Walter Johnson who is second on the list. Young was elected to the National Baseball Hall of Fame in 1937. One year after Young's death, the Cy Young Award was created to honor the previous season's best pitcher. In addition to wins, Young still holds the major league records for most career innings pitched (7,355), most career games started (815), and most complete games (749). He also retired with 316 losses , the most in MLB history. Young's 76 career shutouts are fourth all-time. He also won at least 30 games in a season five times, with ten other seasons of 20 or more wins. In addition, Young pitched three no-hitters , including the third perfect game in baseball history, first in baseball's \"modern era\". In 1999, 88 years after his final major league appearance and 44 years after his death, editors at The Sporting News ranked Cy Young 14th on their list of \"Baseball's 100 Greatest Players\". That same year, baseball fans named him to the Major League Baseball All-Century Team . Young's career started in 1890 with the Cleveland Spiders . After eight years with the Spiders, Young was moved to St. Louis in 1899. After two years there, Young jumped to the newly-created American League , joining the Boston franchise. He was traded back to Cleveland in 1909, before spending the final two months of his career with the Boston Rustlers . After his retirement, Young went back to his farm in Ohio , where he stayed until his death at age 88 in 1955.   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          document_text_with_emphasis  \\\n",
                            "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           African immigration to the United States refers to immigrants to the United States who are or were nationals of Africa . The term African in the scope of this article refers to geographical or national origins rather than racial affiliation. From the Immigration and Nationality Act of 1965 to 2007, an estimated total of 0.8 to 0.9 million Africans immigrated to the United States, accounting for roughly 3.3% of total immigration to the United States during this period. African immigrants in the United States come from almost all regions in Africa and do not constitute a homogeneous group. They include people from different national, linguistic, ethnic, racial, cultural and social backgrounds. AS SUCH, AFRICAN IMMIGRANTS ARE TO BE DISTINGUISHED FROM AFRICAN AMERICAN PEOPLE, THE LATTER OF WHOM ARE DESCENDANTS OF MOSTLY WEST AND CENTRAL AFRICANS WHO WERE INVOLUNTARILY BROUGHT TO THE UNITED STATES BY MEANS OF THE HISTORIC ATLANTIC SLAVE TRADE .   \n",
                            "1  POINTS, SOMETIMES ALSO CALLED A \"DISCOUNT POINT\", ARE A FORM OF PRE-PAID INTEREST . One point equals one percent of the loan amount. By charging a borrower points, a lender effectively increases the yield on the loan above the amount of the stated interest rate . Borrowers can offer to pay a lender points as a method to reduce the interest rate on the loan, thus obtaining a lower monthly payment in exchange for this up-front payment. For each point purchased, the loan rate is typically reduced by 1/8% (0.125%). Paying Points represent a calculated gamble on the part of the buyer. There will be a specific point in the timeline of the loan where the money spent to buy down the interest rate will be equal to the money saved by making reduced loan payments resulting from the lower interest rate on the loan. Selling the property or refinancing prior to this break-even point will result in a net financial loss for the buyer while keeping the loan for longer than this break-even point will result in a net financial savings for the buyer. The longer you keep the property financed under the loan with purchased points, the more the money spent on the points will pay off. Accordingly, if the intention is to buy and sell the property or refinance in a rapid fashion, buying points is actually going to end up costing more than just paying the loan at the higher interest rate. Points may also be purchased to reduce the monthly payment for the purpose of qualifying for a loan. Loan qualification based on monthly income versus the monthly loan payment may sometimes only be achievable by reducing the monthly payment through the purchasing of points to buy down the interest rate, thereby reducing the monthly loan payment. Discount points may be different from origination fee or broker fee . Discount points are always used to buy down the interest rates, while origination fees sometimes are fees the lender charges for the loan or sometimes just another name for buying down the interest rate. Origination fee and discount points are both items listed under lender-charges on the HUD-1 Settlement Statement . The difference in savings over the life of the loan can make paying points a benefit to the borrower. If you intend to stay in your home for an extended period of time, it may be worthwhile to pay additional points in order to obtain a lower interest rate. Any significant changes in fees should be re-disclosed in the final good faith estimate (GFE). Also directly related to points is the concept of the ' no closing cost loan '. If points are paid to acquire a loan, it is impossible at the same time for a broker bank or lender to make a premium for a higher rate. When premium is earned by making the note rate higher, this premium is sometimes used to pay the closing costs.   \n",
                            "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               311 (pronounced \"three-eleven\") is an American rock band from Omaha , Nebraska . The band was formed in 1988 by vocalist/guitarist Nick Hexum , lead guitarist Jim Watson (who would later be replaced by Tim Mahoney), bassist Aaron \"P-Nut\" Wills and drummer Chad Sexton. In 1992, Doug \"SA\" Martinez joined to sing and provide turntables for 311's later albums, rounding out the current line-up. 311 is generally known as an alternative rock band, but it is also classified as rap rock , rap metal , funk rock , funk metal , reggae and jazz fusion . The band's name originates from the police code for indecent exposure in Omaha, Nebraska, after the original guitarist for the band was arrested for streaking . After a series of independent releases, 311 was signed to Capricorn Records in 1992 and released the albums Music (1993) and Grassroots (1994) to moderate success. They achieved greater success with their 1995 triple platinum self-titled album , which reached No. 12 on the Billboard 200 on the strength of the singles \" Down \" and \" All Mixed Up \", the former of which topped the Billboard Hot Modern Rock Tracks in 1996. The band's next three albums, Transistor (1997), Soundsystem (1999) and From Chaos (2001), did not achieve the massive success of the self-titled album, though they were still successful, with the first going platinum and the last two going gold. Their 2004 compilation album Greatest Hits '93–'03 was also certified gold. The band's most recent studio album is 2011's Universal Pulse . To date, 311 has released ten studio albums, one live album, four compilation albums, four EPs and four DVDs. As of 2011, 311 has sold over 8.5 million records in the US. They are currently working on a new album, which is due for release in 2013.   \n",
                            "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       INTERLIBRARY LOAN (ABBREVIATED ILL, AND SOMETIMES CALLED INTERLOAN, DOCUMENT DELIVERY, OR DOCUMENT SUPPLY) IS A SERVICE WHEREBY A USER OF ONE LIBRARY CAN BORROW BOOKS OR RECEIVE PHOTOCOPIES OF DOCUMENTS THAT ARE OWNED BY ANOTHER LIBRARY. THE USER MAKES A REQUEST WITH THEIR LOCAL LIBRARY, WHICH, ACTING AS AN INTERMEDIARY, IDENTIFIES OWNERS OF THE DESIRED ITEM, PLACES THE REQUEST, RECEIVES THE ITEM, MAKES IT AVAILABLE TO THE USER, AND ARRANGES FOR ITS RETURN. The lending library usually sets the due date and overdue fees of the material borrowed. Although books and journal articles are the most frequently requested items, some libraries will lend audio recordings, video recordings, maps, sheet music, and microforms of all kinds. In many cases, nominal fees accompany interlibrary loan services. The term document delivery may also be used for a related service, namely the supply of journal articles and other copies on a personalized basis, whether these come from other libraries or direct from publishers. The end user is usually responsible for any fees, such as costs for postage or photocopying. Commercial document delivery services will borrow on behalf of any customer willing to pay their rates.   \n",
                            "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Denton True \"Cy\" Young (March 29, 1867 – November 4, 1955) was an American Major League Baseball pitcher . During his 22-year baseball career (1890–1911), he pitched for five different teams. Young established numerous pitching records, some of which have stood for a century. Young compiled 511 wins , which is most in Major League history and 94 ahead of Walter Johnson who is second on the list. Young was elected to the National Baseball Hall of Fame in 1937. One year after Young's death, the Cy Young Award was created to honor the previous season's best pitcher. In addition to wins, Young still holds the major league records for most career innings pitched (7,355), most career games started (815), and most complete games (749). He also retired with 316 losses , the most in MLB history. Young's 76 career shutouts are fourth all-time. He also won at least 30 games in a season five times, with ten other seasons of 20 or more wins. In addition, Young pitched three no-hitters , including the third perfect game in baseball history, first in baseball's \"modern era\". In 1999, 88 years after his final major league appearance and 44 years after his death, editors at The Sporting News ranked Cy Young 14th on their list of \"Baseball's 100 Greatest Players\". That same year, baseball fans named him to the Major League Baseball All-Century Team . Young's career started in 1890 with the Cleveland Spiders . After eight years with the Spiders, Young was moved to St. Louis in 1899. After two years there, Young jumped to the newly-created American League , joining the Boston franchise. He was traded back to Cleveland in 1909, before spending the final two months of his career with the Boston Rustlers . After his retirement, Young went back to his farm in Ohio , where he stayed until his death at age 88 in 1955.   \n",
                            "\n",
                            "   relevant  \n",
                            "0      True  \n",
                            "1      True  \n",
                            "2     False  \n",
                            "3      True  \n",
                            "4     False  "
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = download_benchmark_dataset(\n",
                "    task=\"binary-relevance-classification\", dataset_name=\"wiki_qa-test\"\n",
                ")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Display Binary Relevance Classification Template\n",
                "\n",
                "View the default template used to classify relevance. You can tweak this template and evaluate its performance relative to the default."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "You are comparing a reference text to a question and trying to determine if the reference text\n",
                        "contains information relevant to answering the question. Here is the data:\n",
                        "    [BEGIN DATA]\n",
                        "    ************\n",
                        "    [Question]: {input}\n",
                        "    ************\n",
                        "    [Reference text]: {reference}\n",
                        "    ************\n",
                        "    [END DATA]\n",
                        "Compare the Question above to the Reference text. You must determine whether the Reference text\n",
                        "contains information that can answer the Question. Please focus on whether the very specific\n",
                        "question can be answered by the information in the Reference text.\n",
                        "Your response must be single word, either \"relevant\" or \"unrelated\",\n",
                        "and should not contain any text or characters aside from that word.\n",
                        "\"unrelated\" means that the reference text does not contain an answer to the Question.\n",
                        "\"relevant\" means the reference text contains an answer to the Question.\n"
                    ]
                }
            ],
            "source": [
                "print(RAG_RELEVANCY_PROMPT_TEMPLATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The template variables are:\n",
                "\n",
                "- **input:** the question asked by a user\n",
                "- **reference:** the text of the retrieved document\n",
                "- **output:** a ground-truth relevance label"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configure the LLM\n",
                "\n",
                "Configure your OpenAI API key."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
                "    openai_api_key = getpass(\"🔑 Enter your OpenAI API key: \")\n",
                "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmark Dataset Sample\n",
                "Sample size determines run time\n",
                "Recommend iterating small: 100 samples\n",
                "Then increasing to large test set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sample = df.sample(n=N_EVAL_SAMPLE_SIZE).reset_index(drop=True)\n",
                "df_sample = df_sample.rename(\n",
                "    columns={\n",
                "        \"query_text\": \"input\",\n",
                "        \"document_text\": \"reference\",\n",
                "    },\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LLM Evals: Retrieval Relevance Classifications GPT-4\n",
                "Run relevance against a subset of the data.\n",
                "Instantiate the LLM and set parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
                    ]
                }
            ],
            "source": [
                "model = OpenAIModel(\n",
                "    model_name=\"gpt-4\",\n",
                "    temperature=0.0,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "\"Hello! I'm working perfectly. How can I assist you today?\""
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model(\"Hello world, this is a test if you are working?\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Relevance Classifications\n",
                "\n",
                "Run relevance classifications against a subset of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "34bb58642b6d4e9fabd35ad2a43a3321",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "llm_classify |          | 0/500 (0.0%) | ⏳ 00:00<? | ?it/s"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# The rails is used to hold the output to specific values based on the template\n",
                "# It will remove text such as \",,,\" or \"...\"\n",
                "# Will ensure the binary value expected from the template is returned\n",
                "rails = list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values())\n",
                "relevance_classifications = llm_classify(\n",
                "    dataframe=df_sample,\n",
                "    template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=rails,\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate Classifications\n",
                "\n",
                "Evaluate the predictions against human-labeled ground-truth relevance labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'{hello}'"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "s = \"{{hello}}\"\n",
                "s.format(hello=\"world\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_template = \"\"\"\n",
                "Basic Instruction: Compare the query above to the reference text. You must determine whether the reference text contains information that can help answer the query. First, write out in a step by step manner an EXPLANATION that reasons about how to arrive at the correct answer. Avoid simply stating the correct answer at the outset.\n",
                "\n",
                "Proposed Instruction: Your task is to analyze the provided query and compare it with the content in the reference text to see if the text can assist in addressing the query. Begin your response by systematically presenting a thorough step-by-step explanation of your analytical reasoning. Break down each aspect regarding why parts of the reference are relevant or irrelevant to the query. Please detail any implied or explicit connection and avoid disclosing the final determination immediately; instead, guide the reader through your analysis before revealing the conclusion towards the end.\n",
                "\n",
                "---\n",
                "\n",
                "Follow the following format.\n",
                "\n",
                "Query: a query from the user\n",
                "\n",
                "Reference: a reference document\n",
                "\n",
                "Reasoning: Let's think step by step in order to produce the answer. We ...\n",
                "\n",
                "Analysis and Reasoning: a one-word answer, either 'relevant' or 'irrelevant'\n",
                "\n",
                "---\n",
                "\n",
                "Query: {input}\n",
                "\n",
                "Reference: {reference}\n",
                "\n",
                "Reasoning: Let's think step by step in order to\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "\n",
                "def extract(s):\n",
                "    m = re.search(r\"Analysis and Reasoning: (relevant|irrelevant)\", s, re.IGNORECASE)\n",
                "    if m is None or len(m.groups()) < 1:\n",
                "        return \"\"\n",
                "    lowercase = m.group(1).lower()\n",
                "    if lowercase == \"irrelevant\":\n",
                "        return \"unrelated\"\n",
                "    return \"relevant\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0      unrelated\n",
                            "1      unrelated\n",
                            "2      unrelated\n",
                            "3       relevant\n",
                            "4       relevant\n",
                            "         ...    \n",
                            "495     relevant\n",
                            "496    unrelated\n",
                            "497    unrelated\n",
                            "498     relevant\n",
                            "499     relevant\n",
                            "Name: output, Length: 500, dtype: object"
                        ]
                    },
                    "execution_count": 120,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "relevance_classifications = output_df[\"output\"].map(extract)\n",
                "relevance_classifications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "output\n",
                            "relevant     268\n",
                            "unrelated    219\n",
                            "              13\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 121,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "relevance_classifications.value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "81e2a447aa1c4cbb87cacdbaf5f84d49",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "llm_generate |          | 0/500 (0.0%) | ⏳ 00:00<? | ?it/s"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>output</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>produce the answer. We first need to understand the query, which is asking for the field dimensions for the sport of lacrosse. This would typically include information such as the length and width of the field, the size of the goal area, and other related details. Now, we turn to the reference text. The text provides a detailed description of the sport of lacrosse, including its history, the equipment used, and the rules of the game. It mentions that field lacrosse is a version of the sport played internationally and that it is a full contact outdoor men's sport played with ten players on each team. However, the text does not provide any specific information about the dimensions of the field on which lacrosse is played. Therefore, while the text is about lacrosse, it does not contain the specific information requested in the query.\\n\\nAnalysis and Reasoning: Irrelevant.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>produce the answer. We start by examining the query, which is asking for a specific piece of information: the number of ribs Adam has. Next, we look at the reference text. The text provides a detailed account of the story of Adam and Eve according to the Abrahamic religions. It discusses their creation, their life in the Garden of Eden, and the consequences of their disobedience to God. However, despite the detailed narrative, there is no mention of the number of ribs Adam has. The text does not provide any information on Adam's physical attributes or anatomy. Therefore, the reference text does not contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Irrelevant.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>produce the answer. The query is asking for specific information about Donald Trump's wealth. The reference text provides information about Donald Trump's career and business ventures, such as his role as chairman and president of The Trump Organization and the founder of Trump Entertainment Resorts. It also mentions his extravagant lifestyle and the fact that he is the son of a wealthy real-estate developer. However, the text does not provide any specific figures or estimates about Donald Trump's net worth. Therefore, while the text suggests that Donald Trump is wealthy, it does not provide the specific information needed to answer the query about how rich he is.\\n\\nAnalysis and Reasoning: Irrelevant</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>produce the answer. The query is asking for information on how Ludacris started Disturbing tha Peace. The reference text provides information that Ludacris, along with his manager Chaka Zulu and Zulu's brother Jeff Dixon, founded Disturbing tha Peace. However, the reference text does not provide specific details on how they started the record label, such as the process they went through, the challenges they faced, or the motivation behind its creation. \\n\\nAnalysis and Reasoning: Relevant</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>produce the answer. We start by examining the query, which is asking for a definition or explanation of what sado masochism is. The reference text provides a detailed explanation of sadomasochism, including its relation to pleasure, pain, and humiliation, its connection to BDSM, the roles of sadist and masochist, the concept of a switch, and the use of the acronym SM or S/M. It also clarifies that sadomasochism is not considered a clinical paraphilia unless it leads to significant distress or impairment. Therefore, the reference text directly addresses the query and provides comprehensive information about sado masochism.\\n\\nAnalysis and Reasoning: Relevant.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>495</th>\n",
                            "      <td>produce the answer. We start by identifying the query, which is asking for the population of San Francisco. Next, we examine the reference text to see if it contains this information. The text provides a detailed description of San Francisco, including its history, cultural significance, and geographical details. Importantly, it also mentions the population of San Francisco, stating that it was 805,235 as of the 2010 Census. Therefore, the reference text does contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Relevant</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>496</th>\n",
                            "      <td>produce the answer. We first look at the query, which is asking for the real address of the character SpongeBob. This means we need to find specific information about where SpongeBob lives. Now, we examine the reference text. The text provides a lot of information about the SpongeBob SquarePants television series, including its creation, popularity, and the people involved in its production. It also mentions that the series is set in the underwater city of Bikini Bottom. However, it does not provide a specific address for SpongeBob within Bikini Bottom. Therefore, while the text does provide some relevant information about the setting of the series, it does not provide the specific information needed to answer the query.\\n\\nAnalysis and Reasoning: Irrelevant</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>497</th>\n",
                            "      <td>produce the answer. We first need to identify if the reference text provides any information about when Harley-Davidson releases new year models. The reference text provides a brief history of Harley-Davidson, including its founding, survival through the Great Depression, and competition with Japanese manufacturers. It also discusses the types of motorcycles the company sells, the customization tradition, and the company's attempts to establish itself in the light motorcycle market. It also mentions the company's brand community, events, and a museum, as well as licensing of the brand and logo. However, there is no mention of when Harley-Davidson releases new year models. Therefore, the reference text does not contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Irrelevant</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>498</th>\n",
                            "      <td>produce the answer. We first look at the query, which is asking about the cause of the shapes in the Giant's Causeway. The reference text provides information about the Giant's Causeway, including its location, its status as a World Heritage Site and a National Nature Reserve, and its popularity as a tourist attraction. However, the most relevant part of the text to the query is the description of the Causeway as an area of about 40,000 interlocking basalt columns, which are the result of an ancient volcanic eruption. This suggests that the shapes in the Giant's Causeway were caused by this volcanic activity. The text also mentions that most of the columns are hexagonal, and some have four, five, seven or eight sides. This provides additional information about the shapes in the Giant's Causeway. \\n\\nAnalysis and Reasoning: Relevant.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>499</th>\n",
                            "      <td>produce the answer. We first look at the query, which is asking for the number of bass species. The reference text provides information about bass fishing and mentions several species of bass, including largemouth bass, smallmouth bass, Spotted bass or Kentucky bass, and Guadalupe bass. It also mentions that there are many other species and subspecies of the genus Micropterus, which are all considered bass. However, the text does not provide a specific number of bass species. Therefore, while the reference text does provide some information about different types of bass, it does not directly answer the query about the total number of bass species.\\n\\nAnalysis and Reasoning: Relevant</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>500 rows × 1 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 output\n",
                            "0    produce the answer. We first need to understand the query, which is asking for the field dimensions for the sport of lacrosse. This would typically include information such as the length and width of the field, the size of the goal area, and other related details. Now, we turn to the reference text. The text provides a detailed description of the sport of lacrosse, including its history, the equipment used, and the rules of the game. It mentions that field lacrosse is a version of the sport played internationally and that it is a full contact outdoor men's sport played with ten players on each team. However, the text does not provide any specific information about the dimensions of the field on which lacrosse is played. Therefore, while the text is about lacrosse, it does not contain the specific information requested in the query.\\n\\nAnalysis and Reasoning: Irrelevant.\n",
                            "1                                                                                                                                                                                              produce the answer. We start by examining the query, which is asking for a specific piece of information: the number of ribs Adam has. Next, we look at the reference text. The text provides a detailed account of the story of Adam and Eve according to the Abrahamic religions. It discusses their creation, their life in the Garden of Eden, and the consequences of their disobedience to God. However, despite the detailed narrative, there is no mention of the number of ribs Adam has. The text does not provide any information on Adam's physical attributes or anatomy. Therefore, the reference text does not contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Irrelevant.\n",
                            "2                                                                                                                                                                                produce the answer. The query is asking for specific information about Donald Trump's wealth. The reference text provides information about Donald Trump's career and business ventures, such as his role as chairman and president of The Trump Organization and the founder of Trump Entertainment Resorts. It also mentions his extravagant lifestyle and the fact that he is the son of a wealthy real-estate developer. However, the text does not provide any specific figures or estimates about Donald Trump's net worth. Therefore, while the text suggests that Donald Trump is wealthy, it does not provide the specific information needed to answer the query about how rich he is.\\n\\nAnalysis and Reasoning: Irrelevant\n",
                            "3                                                                                                                                                                                                                                                                                                                                                                                                         produce the answer. The query is asking for information on how Ludacris started Disturbing tha Peace. The reference text provides information that Ludacris, along with his manager Chaka Zulu and Zulu's brother Jeff Dixon, founded Disturbing tha Peace. However, the reference text does not provide specific details on how they started the record label, such as the process they went through, the challenges they faced, or the motivation behind its creation. \\n\\nAnalysis and Reasoning: Relevant\n",
                            "4                                                                                                                                                                                                                            produce the answer. We start by examining the query, which is asking for a definition or explanation of what sado masochism is. The reference text provides a detailed explanation of sadomasochism, including its relation to pleasure, pain, and humiliation, its connection to BDSM, the roles of sadist and masochist, the concept of a switch, and the use of the acronym SM or S/M. It also clarifies that sadomasochism is not considered a clinical paraphilia unless it leads to significant distress or impairment. Therefore, the reference text directly addresses the query and provides comprehensive information about sado masochism.\\n\\nAnalysis and Reasoning: Relevant.\n",
                            "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...\n",
                            "495                                                                                                                                                                                                                                                                                                                                             produce the answer. We start by identifying the query, which is asking for the population of San Francisco. Next, we examine the reference text to see if it contains this information. The text provides a detailed description of San Francisco, including its history, cultural significance, and geographical details. Importantly, it also mentions the population of San Francisco, stating that it was 805,235 as of the 2010 Census. Therefore, the reference text does contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Relevant\n",
                            "496                                                                                                                    produce the answer. We first look at the query, which is asking for the real address of the character SpongeBob. This means we need to find specific information about where SpongeBob lives. Now, we examine the reference text. The text provides a lot of information about the SpongeBob SquarePants television series, including its creation, popularity, and the people involved in its production. It also mentions that the series is set in the underwater city of Bikini Bottom. However, it does not provide a specific address for SpongeBob within Bikini Bottom. Therefore, while the text does provide some relevant information about the setting of the series, it does not provide the specific information needed to answer the query.\\n\\nAnalysis and Reasoning: Irrelevant\n",
                            "497                                                                           produce the answer. We first need to identify if the reference text provides any information about when Harley-Davidson releases new year models. The reference text provides a brief history of Harley-Davidson, including its founding, survival through the Great Depression, and competition with Japanese manufacturers. It also discusses the types of motorcycles the company sells, the customization tradition, and the company's attempts to establish itself in the light motorcycle market. It also mentions the company's brand community, events, and a museum, as well as licensing of the brand and logo. However, there is no mention of when Harley-Davidson releases new year models. Therefore, the reference text does not contain information that can help answer the query.\\n\\nAnalysis and Reasoning: Irrelevant\n",
                            "498                                        produce the answer. We first look at the query, which is asking about the cause of the shapes in the Giant's Causeway. The reference text provides information about the Giant's Causeway, including its location, its status as a World Heritage Site and a National Nature Reserve, and its popularity as a tourist attraction. However, the most relevant part of the text to the query is the description of the Causeway as an area of about 40,000 interlocking basalt columns, which are the result of an ancient volcanic eruption. This suggests that the shapes in the Giant's Causeway were caused by this volcanic activity. The text also mentions that most of the columns are hexagonal, and some have four, five, seven or eight sides. This provides additional information about the shapes in the Giant's Causeway. \\n\\nAnalysis and Reasoning: Relevant.\n",
                            "499                                                                                                                                                                                                 produce the answer. We first look at the query, which is asking for the number of bass species. The reference text provides information about bass fishing and mentions several species of bass, including largemouth bass, smallmouth bass, Spotted bass or Kentucky bass, and Guadalupe bass. It also mentions that there are many other species and subspecies of the genus Micropterus, which are all considered bass. However, the text does not provide a specific number of bass species. Therefore, while the reference text does provide some information about different types of bass, it does not directly answer the query about the total number of bass species.\\n\\nAnalysis and Reasoning: Relevant\n",
                            "\n",
                            "[500 rows x 1 columns]"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from phoenix.evals import llm_generate\n",
                "\n",
                "output_df = llm_generate(df_sample, prompt_template, model=model)\n",
                "output_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0      unrelated\n",
                            "1      unrelated\n",
                            "2      unrelated\n",
                            "3       relevant\n",
                            "4       relevant\n",
                            "         ...    \n",
                            "495     relevant\n",
                            "496    unrelated\n",
                            "497    unrelated\n",
                            "498     relevant\n",
                            "499     relevant\n",
                            "Name: output, Length: 500, dtype: object"
                        ]
                    },
                    "execution_count": 123,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "relevance_classifications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    relevant       0.65      0.90      0.76       194\n",
                        "   unrelated       0.93      0.66      0.77       306\n",
                        "\n",
                        "   micro avg       0.78      0.76      0.77       500\n",
                        "   macro avg       0.79      0.78      0.77       500\n",
                        "weighted avg       0.82      0.76      0.77       500\n",
                        "\n"
                    ]
                },
                {
                    "ename": "pycmVectorError",
                    "evalue": "The type of input vectors is assumed to be a list or a NumPy array",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mpycmVectorError\u001b[0m                           Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m df_sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevant\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(RAG_RELEVANCY_PROMPT_RAILS_MAP)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(true_labels, relevance_classifications, labels\u001b[38;5;241m=\u001b[39mrails))\n\u001b[0;32m----> 4\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mConfusionMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactual_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelevance_classifications\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrails\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m confusion_matrix\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      8\u001b[0m     cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcolormaps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m     number_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     normalized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m )\n",
                        "File \u001b[0;32m~/phoenix/.venv/lib/python3.12/site-packages/pycm/pycm_obj.py:97\u001b[0m, in \u001b[0;36mConfusionMatrix.__init__\u001b[0;34m(self, actual_vector, predict_vector, matrix, digit, threshold, file, sample_weight, transpose, classes, is_imbalanced, metrics_off)\u001b[0m\n\u001b[1;32m     94\u001b[0m     matrix_param \u001b[38;5;241m=\u001b[39m __obj_array_handler__(\n\u001b[1;32m     95\u001b[0m         matrix, classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     matrix_param \u001b[38;5;241m=\u001b[39m \u001b[43m__obj_vector_handler__\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m __obj_assign_handler__(\u001b[38;5;28mself\u001b[39m, matrix_param)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metrics_off:\n",
                        "File \u001b[0;32m~/phoenix/.venv/lib/python3.12/site-packages/pycm/pycm_handler.py:226\u001b[0m, in \u001b[0;36m__obj_vector_handler__\u001b[0;34m(cm, actual_vector, predict_vector, threshold, sample_weight, classes)\u001b[0m\n\u001b[1;32m    223\u001b[0m     cm\u001b[38;5;241m.\u001b[39mpredict_vector \u001b[38;5;241m=\u001b[39m predict_vector\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(actual_vector, (\u001b[38;5;28mlist\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \\\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(predict_vector, (\u001b[38;5;28mlist\u001b[39m, numpy\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pycmVectorError(VECTOR_TYPE_ERROR)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual_vector) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(predict_vector):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pycmVectorError(VECTOR_SIZE_ERROR)\n",
                        "\u001b[0;31mpycmVectorError\u001b[0m: The type of input vectors is assumed to be a list or a NumPy array"
                    ]
                }
            ],
            "source": [
                "true_labels = df_sample[\"relevant\"].map(RAG_RELEVANCY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, relevance_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=relevance_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Classifications with explanations\n",
                "\n",
                "When evaluating a dataset for relevance, it can be useful to know why the LLM classified a document as relevant or irrelevant. The following code block runs `llm_classify` with explanations turned on so that we can inspect why the LLM made the classification it did. There is speed tradeoff since more tokens is being generated but it can be highly informative when troubleshooting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "small_df_sample = df_sample.copy().sample(n=5).reset_index(drop=True)\n",
                "relevance_classifications_df = llm_classify(\n",
                "    dataframe=small_df_sample,\n",
                "    template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=rails,\n",
                "    provide_explanation=True,\n",
                "    verbose=True,\n",
                "    concurrency=20,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's view the data\n",
                "merged_df = pd.merge(\n",
                "    small_df_sample, relevance_classifications_df, left_index=True, right_index=True\n",
                ")\n",
                "merged_df[[\"input\", \"reference\", \"label\", \"explanation\"]].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LLM Evals: relevance Classifications GPT-3.5 Turbo\n",
                "Run relevance against a subset of the data using GPT-3.5. GPT-3.5 can significantly speed up the classification process. However there are tradeoffs as  we will see below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = OpenAIModel(model=\"gpt-3.5-turbo\", temperature=0.0, request_timeout=20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rails = list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values())\n",
                "relevance_classifications = llm_classify(\n",
                "    dataframe=df_sample,\n",
                "    template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=rails,\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "true_labels = df_sample[\"relevant\"].map(RAG_RELEVANCY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, relevance_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=relevance_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preview: Running with GPT-4 Turbo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = OpenAIModel(model_name=\"gpt-4-turbo-preview\")\n",
                "relevance_classifications = llm_classify(\n",
                "    dataframe=df_sample,\n",
                "    template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
                "    model=model,\n",
                "    rails=list(RAG_RELEVANCY_PROMPT_RAILS_MAP.values()),\n",
                "    concurrency=20,\n",
                ")[\"label\"].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "true_labels = df_sample[\"relevant\"].map(RAG_RELEVANCY_PROMPT_RAILS_MAP).tolist()\n",
                "\n",
                "print(classification_report(true_labels, relevance_classifications, labels=rails))\n",
                "confusion_matrix = ConfusionMatrix(\n",
                "    actual_vector=true_labels, predict_vector=relevance_classifications, classes=rails\n",
                ")\n",
                "confusion_matrix.plot(\n",
                "    cmap=plt.colormaps[\"Blues\"],\n",
                "    number_label=True,\n",
                "    normalized=True,\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
