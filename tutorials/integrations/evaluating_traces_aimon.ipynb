{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
    "        <br>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically find the bad LLM responses in your LLM Evals with AIMon\n",
    "\n",
    "This guide will walk you through the process of evaluating LLM responses captured in Phoenix with AIMon's proprietary evaluation models.\n",
    "\n",
    "AIMon offers a set of models and evaluation tools to test and benchmark the performance of your LLM apps and Agents. This notebook shows how you can run evals powered by AIMon models over Phoenix traces, and view results in your dashboard.\n",
    "\n",
    "This guide requires an AIMon API key. If you don't have one, you can sign up for a free trial [here](https://app.aimon.ai/?screen=signup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies & Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q \"arize-phoenix>=4.29.0\"\n",
    "pip install -q 'httpx<0.28'\n",
    "pip install -q openai aimon openinference-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sign up for a free trial of AIMon and get an API key [here](https://www.aimon.ai/).\n",
    "if not (aimon_api_key := os.getenv(\"AIMON_API_KEY\")):\n",
    "    aimon_api_key = getpass(\"ðŸ”‘ Enter your AIMon API key: \")\n",
    "\n",
    "os.environ[\"AIMON_API_KEY\"] = aimon_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll use Phoenix as our destination. You could instead add any other exporters you'd like in this approach.\n",
    "\n",
    "If you need to set up an API key for Phoenix, you can do so [here](https://app.phoenix.arize.com/).\n",
    "\n",
    "The code below will connect you to a Phoenix Cloud instance. You can also connect to [a self-hosted Phoenix instance](https://docs.arize.com/phoenix/deployment) if you'd prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Phoenix API Key for tracing\n",
    "if not (PHOENIX_API_KEY := os.getenv(\"PHOENIX_CLIENT_HEADERS\")):\n",
    "    PHOENIX_API_KEY = getpass(\"ðŸ”‘ Enter your Phoenix API Key: \")\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have Phoenix configured, we can register that instance with OpenTelemetry, which will allow us to collect traces from our application here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=\"evaluating_traces_aimon\", endpoint=\"http://localhost:6006/v1/traces\"\n",
    ")\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare trace dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of making this guide fully runnable, we'll briefly generate some traces and track them in Phoenix. Typically, you would have already captured traces in Phoenix and would skip to \"Download trace dataset from Phoenix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimon import Detect\n",
    "from openai import OpenAI\n",
    "\n",
    "detect = Detect(\n",
    "    values_returned=[\"context\", \"generated_text\"],\n",
    "    config={\"hallucination\": {\"detector_name\": \"default\"}},\n",
    "    publish=True,\n",
    "    api_key=os.getenv(\"AIMON_API_KEY\"),\n",
    "    application_name=\"my_awesome_llm_app\",\n",
    "    model_name=\"my_awesome_llm_model\",\n",
    ")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Function to generate an answer\n",
    "@detect\n",
    "def generate_answers(question_with_context):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a question and answer tool that occasionally hallucinates.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {question_with_context['question']}\\nContext: {question_with_context['context']}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    generated_text = response.choices[0].message.content\n",
    "    return question_with_context[\"context\"], generated_text\n",
    "\n",
    "\n",
    "questions_with_context = [\n",
    "    {\n",
    "        \"question\": \"What is the 3rd month of the year in alphabetical order?\",\n",
    "        \"context\": \"The twelve months of the year in alphabetical order are: April, August, December, February, January, July, June, March, May, November, October, September.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"context\": \"France is a country in Western Europe with several major cities including Paris, Lyon, Marseille, and Nice.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many seconds are in 100 years?\",\n",
    "        \"context\": \"There are 365 days in a regular year and 366 days in a leap year. Every 4 years is a leap year, except for years divisible by 100 but not by 400.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Alice, Bob, and Charlie went to a cafÃ©. Alice paid twice as much as Bob, and Bob paid three times as much as Charlie. If the total bill was $72, how much did each person pay?\",\n",
    "        \"context\": \"To solve this problem, you need to set up equations based on the given relationships and solve for the variables.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When was the Declaration of Independence signed?\",\n",
    "        \"context\": \"The Continental Congress declared independence from Great Britain on July 2, 1776, and the Declaration was officially adopted two days later.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from opentelemetry.trace import format_span_id, get_current_span\n",
    "\n",
    "httpx_client = httpx.Client()\n",
    "\n",
    "\n",
    "@tracer.chain\n",
    "def run_question(question):\n",
    "    _, generated_text, aimon_response = generate_answers(question)\n",
    "\n",
    "    span = get_current_span()\n",
    "    span_id = format_span_id(span.get_span_context().span_id)\n",
    "\n",
    "    label = aimon_response.detect_response.model_dump().get(\"hallucination\").get(\"is_hallucinated\")\n",
    "    score = aimon_response.detect_response.model_dump().get(\"hallucination\").get(\"score\")\n",
    "\n",
    "    annotation_payload = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"span_id\": span_id,\n",
    "                \"name\": \"aimon hallucination eval\",\n",
    "                \"annotator_kind\": \"LLM\",\n",
    "                \"result\": {\"label\": label, \"score\": score},\n",
    "                \"metadata\": {},\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    headers = {\"api_key\": os.getenv(\"PHOENIX_API_KEY\")}\n",
    "\n",
    "    httpx_client.post(\n",
    "        os.getenv(\"PHOENIX_COLLECTOR_ENDPOINT\") + \"/v1/span_annotations?sync=false\",\n",
    "        json=annotation_payload,\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "for question in questions_with_context:\n",
    "    run_question(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see evaluations in the Phoenix UI!\n",
    "\n",
    "\n",
    "\n",
    "From here you can continue collecting and evaluating traces!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
