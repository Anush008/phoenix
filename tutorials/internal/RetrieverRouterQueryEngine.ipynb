{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Retriever Router Query Engine\n",
                "In this tutorial, we define a router query engine based on a retriever. The retriever will select a set of nodes, and we will in turn select the right QueryEngine.\n",
                "\n",
                "We use our new `ToolRetrieverRouterQueryEngine` class for this! "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# NOTE: This is ONLY necessary in jupyter notebook.\n",
                "# Details: Jupyter runs an event-loop behind the scenes.\n",
                "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
                "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
                "import nest_asyncio\n",
                "\n",
                "nest_asyncio.apply()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
                "\n",
                "from llama_index import (\n",
                "    VectorStoreIndex,\n",
                "    SummaryIndex,\n",
                "    SimpleDirectoryReader,\n",
                "    ServiceContext,\n",
                "    StorageContext,\n",
                ")\n",
                "import phoenix as px\n",
                "from phoenix.trace.llama_index import OpenInferenceTraceCallbackHandler\n",
                "from llama_index.callbacks import CallbackManager\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üåç To view the Phoenix app in your browser, visit http://127.0.0.1:6060/\n",
                        "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
                        "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<phoenix.session.session.ThreadSession at 0x107f9f970>"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "px.launch_app()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Data\n",
                "\n",
                "We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# load documents\n",
                "documents = SimpleDirectoryReader(\n",
                "    \"/Users/xandersong/llama_index/docs/examples/data/paul_graham\"\n",
                ").load_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# initialize service context (set chunk size)\n",
                "\n",
                "callback_handler = OpenInferenceTraceCallbackHandler()\n",
                "service_context = ServiceContext.from_defaults(\n",
                "    chunk_size=1024, callback_manager=CallbackManager(handlers=[callback_handler])\n",
                ")\n",
                "nodes = service_context.node_parser.get_nodes_from_documents(documents)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# initialize storage context (by default it's in-memory)\n",
                "storage_context = StorageContext.from_defaults()\n",
                "storage_context.docstore.add_documents(nodes)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Define Summary Index and Vector Index over Same Data "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
                "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Define Query Engine and Tool for these Indices\n",
                "\n",
                "We define a Query Engine for each Index. We then wrap these with our `QueryEngineTool`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index.tools.query_engine import QueryEngineTool\n",
                "\n",
                "list_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True)\n",
                "vector_query_engine = vector_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True)\n",
                "\n",
                "list_tool = QueryEngineTool.from_defaults(\n",
                "    query_engine=list_query_engine,\n",
                "    description=\"Useful for questions asking for a biography of the author.\",\n",
                ")\n",
                "vector_tool = QueryEngineTool.from_defaults(\n",
                "    query_engine=vector_query_engine,\n",
                "    description=\"Useful for retrieving specific snippets from the author's life, like his time in college, his time in YC, or more.\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Define Retrieval-Augmented Router Query Engine\n",
                "\n",
                "We define a router query engine that's augmented with a retrieval mechanism, to help deal with the case when the set of choices is too large. \n",
                "\n",
                "To do this, we first define an `ObjectIndex` over the set of query engine tools. The `ObjectIndex` is defined an underlying index data structure (e.g. a vector index, keyword index), and can serialize QueryEngineTool objects to/from our indices.\n",
                "\n",
                "We then use our `ToolRetrieverRouterQueryEngine` class, and pass in an `ObjectRetriever` over `QueryEngineTool` objects.\n",
                "The `ObjectRetriever` corresponds to our `ObjectIndex`. \n",
                "\n",
                "This retriever can then dyamically retrieve the relevant query engines during query-time. This allows us to pass in an arbitrary number of query engine tools without worrying about prompt limitations. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index import VectorStoreIndex\n",
                "from llama_index.objects import ObjectIndex, SimpleToolNodeMapping\n",
                "\n",
                "tool_mapping = SimpleToolNodeMapping.from_objects([list_tool, vector_tool])\n",
                "obj_index = ObjectIndex.from_objects(\n",
                "    [list_tool, vector_tool],\n",
                "    tool_mapping,\n",
                "    VectorStoreIndex,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index.query_engine import ToolRetrieverRouterQueryEngine\n",
                "\n",
                "query_engine = ToolRetrieverRouterQueryEngine(obj_index.as_retriever())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.query_engine.router_query_engine:Combining responses from multiple query engines.\n",
                        "Combining responses from multiple query engines.\n",
                        "Combining responses from multiple query engines.\n",
                        "Combining responses from multiple query engines.\n"
                    ]
                }
            ],
            "source": [
                "response = query_engine.query(\"What is a biography of the author's life?\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.query_engine.router_query_engine:Combining responses from multiple query engines.\n",
                        "Combining responses from multiple query engines.\n"
                    ]
                }
            ],
            "source": [
                "response = query_engine.query(\"What did Paul Graham do during his time in college?\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llmapps",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
