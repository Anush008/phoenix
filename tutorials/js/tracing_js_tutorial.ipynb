{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@opentelemetry/api: Registered a global for diag v1.9.0.\n",
      "@opentelemetry/api: Registered a global for trace v1.9.0.\n",
      "@opentelemetry/api: Registered a global for context v1.9.0.\n",
      "@opentelemetry/api: Registered a global for propagation v1.9.0.\n",
      "ðŸ‘€ OpenInference initialized\n"
     ]
    }
   ],
   "source": [
    "import { OpenAIInstrumentation } from \"npm:@arizeai/openinference-instrumentation-openai\";\n",
    "import { ConsoleSpanExporter } from \"npm:@opentelemetry/sdk-trace-base\";\n",
    "import {\n",
    "  NodeTracerProvider,\n",
    "  SimpleSpanProcessor,\n",
    "} from \"npm:@opentelemetry/sdk-trace-node\";\n",
    "import { Resource } from \"npm:@opentelemetry/resources\";\n",
    "import { OTLPTraceExporter } from \"npm:@opentelemetry/exporter-trace-otlp-proto\";\n",
    "import { SemanticResourceAttributes } from \"npm:@opentelemetry/semantic-conventions\";\n",
    "import { diag, DiagConsoleLogger, DiagLogLevel } from \"npm:@opentelemetry/api\";\n",
    "\n",
    "// For troubleshooting, set the log level to DiagLogLevel.DEBUG\n",
    "diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\n",
    "\n",
    "const provider = new NodeTracerProvider({\n",
    "  resource: new Resource({\n",
    "    [SemanticResourceAttributes.SERVICE_NAME]: \"openai-service\",\n",
    "  }),\n",
    "});\n",
    "\n",
    "provider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\n",
    "provider.addSpanProcessor(\n",
    "  new SimpleSpanProcessor(\n",
    "    new OTLPTraceExporter({\n",
    "      url: \"http://localhost:6006/v1/traces\",\n",
    "    }),\n",
    "  ),\n",
    ");\n",
    "\n",
    "const oaiInstrumentor = new OpenAIInstrumentation();\n",
    "\n",
    "provider.register();\n",
    "\n",
    "console.log(\"ðŸ‘€ OpenInference initialized\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from 'npm:openai';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually instrumenting openai\n",
      "Applying patch for openai@undefined\n"
     ]
    }
   ],
   "source": [
    "oaiInstrumentor.manuallyInstrument(OpenAI);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  resource: {\n",
      "    attributes: {\n",
      "      \"service.name\": \"openai-service\",\n",
      "      \"telemetry.sdk.language\": \"nodejs\",\n",
      "      \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "      \"telemetry.sdk.version\": \"1.26.0\"\n",
      "    }\n",
      "  },\n",
      "  instrumentationScope: {\n",
      "    name: \"@arizeai/openinference-instrumentation-openai\",\n",
      "    version: \"0.5.0\",\n",
      "    schemaUrl: undefined\n",
      "  },\n",
      "  traceId: \"17339addb5a1ef2435505d2fd92982b3\",\n",
      "  parentId: undefined,\n",
      "  traceState: undefined,\n",
      "  name: \"OpenAI Chat Completions\",\n",
      "  id: \"4921232c30a77b7c\",\n",
      "  kind: 0,\n",
      "  timestamp: 1727823740296000,\n",
      "  duration: 406757.375,\n",
      "  attributes: {\n",
      "    \"openinference.span.kind\": \"LLM\",\n",
      "    \"llm.model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"input.value\": '{\"messages\":[{\"role\":\"user\",\"content\":\"Say this is a test\"}],\"model\":\"gpt-3.5-turbo\"}',\n",
      "    \"input.mime_type\": \"application/json\",\n",
      "    \"llm.invocation_parameters\": '{\"model\":\"gpt-3.5-turbo\"}',\n",
      "    \"llm.input_messages.0.message.role\": \"user\",\n",
      "    \"llm.input_messages.0.message.content\": \"Say this is a test\",\n",
      "    \"output.value\": '{\"id\":\"chatcmpl-ADgAmTs84ITvCgDhBFp3VEgzqP0lK\",\"object\":\"chat.completion\",\"created\":1727823740,\"model\":\"gpt-3.5-turbo-0125\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"This is a test.\",\"refusal\":null},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":12,\"completion_tokens\":5,\"total_tokens\":17,\"prompt_tokens_details\":{\"cached_tokens\":0},\"completion_tokens_details\":{\"reasoning_tokens\":0}},\"system_fingerprint\":null}',\n",
      "    \"output.mime_type\": \"application/json\",\n",
      "    \"llm.output_messages.0.message.role\": \"assistant\",\n",
      "    \"llm.output_messages.0.message.content\": \"This is a test.\",\n",
      "    \"llm.token_count.completion\": 5,\n",
      "    \"llm.token_count.prompt\": 12,\n",
      "    \"llm.token_count.total\": 17\n",
      "  },\n",
      "  status: { code: 1 },\n",
      "  events: [],\n",
      "  links: []\n",
      "}\n",
      "items to be sent [\n",
      "  Span {\n",
      "    attributes: {\n",
      "      \"openinference.span.kind\": \"LLM\",\n",
      "      \"llm.model_name\": \"gpt-3.5-turbo-0125\",\n",
      "      \"input.value\": '{\"messages\":[{\"role\":\"user\",\"content\":\"Say this is a test\"}],\"model\":\"gpt-3.5-turbo\"}',\n",
      "      \"input.mime_type\": \"application/json\",\n",
      "      \"llm.invocation_parameters\": '{\"model\":\"gpt-3.5-turbo\"}',\n",
      "      \"llm.input_messages.0.message.role\": \"user\",\n",
      "      \"llm.input_messages.0.message.content\": \"Say this is a test\",\n",
      "      \"output.value\": '{\"id\":\"chatcmpl-ADgAmTs84ITvCgDhBFp3VEgzqP0lK\",\"object\":\"chat.completion\",\"created\":1727823740,\"model\":\"gpt-3.5-turbo-0125\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"This is a test.\",\"refusal\":null},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":12,\"completion_tokens\":5,\"total_tokens\":17,\"prompt_tokens_details\":{\"cached_tokens\":0},\"completion_tokens_details\":{\"reasoning_tokens\":0}},\"system_fingerprint\":null}',\n",
      "      \"output.mime_type\": \"application/json\",\n",
      "      \"llm.output_messages.0.message.role\": \"assistant\",\n",
      "      \"llm.output_messages.0.message.content\": \"This is a test.\",\n",
      "      \"llm.token_count.completion\": 5,\n",
      "      \"llm.token_count.prompt\": 12,\n",
      "      \"llm.token_count.total\": 17\n",
      "    },\n",
      "    links: [],\n",
      "    events: [],\n",
      "    _droppedAttributesCount: 0,\n",
      "    _droppedEventsCount: 0,\n",
      "    _droppedLinksCount: 0,\n",
      "    status: { code: 1 },\n",
      "    endTime: [ 1727823740, 702757375 ],\n",
      "    _ended: true,\n",
      "    _duration: [ 0, 406757375 ],\n",
      "    name: \"OpenAI Chat Completions\",\n",
      "    _spanContext: {\n",
      "      traceId: \"17339addb5a1ef2435505d2fd92982b3\",\n",
      "      spanId: \"4921232c30a77b7c\",\n",
      "      traceFlags: 1,\n",
      "      traceState: undefined\n",
      "    },\n",
      "    parentSpanId: undefined,\n",
      "    kind: 0,\n",
      "    _performanceStartTime: 60995.106708,\n",
      "    _performanceOffset: -10.106689453125,\n",
      "    _startTimeProvided: false,\n",
      "    startTime: [ 1727823740, 296000000 ],\n",
      "    resource: Resource {\n",
      "      _attributes: {\n",
      "        \"service.name\": \"openai-service\",\n",
      "        \"telemetry.sdk.language\": \"nodejs\",\n",
      "        \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "        \"telemetry.sdk.version\": \"1.26.0\"\n",
      "      },\n",
      "      asyncAttributesPending: false,\n",
      "      _syncAttributes: {\n",
      "        \"service.name\": \"openai-service\",\n",
      "        \"telemetry.sdk.language\": \"nodejs\",\n",
      "        \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "        \"telemetry.sdk.version\": \"1.26.0\"\n",
      "      },\n",
      "      _asyncAttributesPromise: undefined\n",
      "    },\n",
      "    instrumentationLibrary: {\n",
      "      name: \"@arizeai/openinference-instrumentation-openai\",\n",
      "      version: \"0.5.0\",\n",
      "      schemaUrl: undefined\n",
      "    },\n",
      "    _spanLimits: {\n",
      "      attributeValueLengthLimit: Infinity,\n",
      "      attributeCountLimit: 128,\n",
      "      linkCountLimit: 128,\n",
      "      eventCountLimit: 128,\n",
      "      attributePerEventCountLimit: 128,\n",
      "      attributePerLinkCountLimit: 128\n",
      "    },\n",
      "    _attributeValueLengthLimit: Infinity,\n",
      "    _spanProcessor: MultiSpanProcessor {\n",
      "      _spanProcessors: [\n",
      "        SimpleSpanProcessor {\n",
      "          _exporter: ConsoleSpanExporter {},\n",
      "          _shutdownOnce: [BindOnceFuture],\n",
      "          _unresolvedExports: Set(0) {}\n",
      "        },\n",
      "        SimpleSpanProcessor {\n",
      "          _exporter: [OTLPTraceExporter],\n",
      "          _shutdownOnce: [BindOnceFuture],\n",
      "          _unresolvedExports: Set(0) {}\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "]\n",
      "{ role: \"assistant\", content: \"This is a test.\", refusal: null }\n"
     ]
    }
   ],
   "source": [
    "const client = new OpenAI({\n",
    "  apiKey: process.env['OPENAI_API_KEY'], // This is the default and can be omitted\n",
    "});\n",
    "\n",
    "async function main() {\n",
    " try {\n",
    "  const chatCompletion = await client.chat.completions.create({\n",
    "    messages: [{ role: 'user', content: 'Say this is a test' }],\n",
    "    model: 'gpt-3.5-turbo',\n",
    "  });\n",
    "  console.dir(chatCompletion.choices[0].message);\n",
    " } catch (e) {\n",
    "   console.error(e);\n",
    " }\n",
    "}\n",
    "\n",
    "await main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
