{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { OpenAIInstrumentation } from \"npm:@arizeai/openinference-instrumentation-openai\";\n",
    "import { ConsoleSpanExporter } from \"npm:@opentelemetry/sdk-trace-base\";\n",
    "import {\n",
    "  NodeTracerProvider,\n",
    "  SimpleSpanProcessor,\n",
    "} from \"npm:@opentelemetry/sdk-trace-node\";\n",
    "import { Resource } from \"npm:@opentelemetry/resources\";\n",
    "import { OTLPTraceExporter } from \"npm:@opentelemetry/exporter-trace-otlp-proto\";\n",
    "import { SemanticResourceAttributes } from \"npm:@opentelemetry/semantic-conventions\";\n",
    "import { diag, DiagConsoleLogger, DiagLogLevel } from \"npm:@opentelemetry/api\";\n",
    "\n",
    "// For troubleshooting, set the log level to DiagLogLevel.DEBUG\n",
    "diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.DEBUG);\n",
    "\n",
    "const provider = new NodeTracerProvider({\n",
    "  resource: new Resource({\n",
    "    [SemanticResourceAttributes.SERVICE_NAME]: \"openai-service\",\n",
    "  }),\n",
    "});\n",
    "\n",
    "provider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));\n",
    "provider.addSpanProcessor(\n",
    "  new SimpleSpanProcessor(\n",
    "    new OTLPTraceExporter({\n",
    "      url: \"http://localhost:6006/v1/traces\",\n",
    "    }),\n",
    "  ),\n",
    ");\n",
    "\n",
    "const oaiInstrumentor = new OpenAIInstrumentation();\n",
    "\n",
    "provider.register();\n",
    "\n",
    "console.log(\"ðŸ‘€ OpenInference initialized\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from 'npm:openai';\n",
    "oaiInstrumentor.manuallyInstrument(OpenAI);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import {getPass} from 'npm:getpass';\n",
    "\n",
    "// const apiKey = await new Promise((resolve, reject) => {\n",
    "//   const existingApiKey = Deno.env.get('OPENAI_API_KEY');\n",
    "//    if (!existingApiKey) { \n",
    "//     getPass({prompt: \"Enter your OpenAI API key ðŸ”‘\"}, (err: Error | undefined, pass: string) => {\n",
    "//       if (err) {\n",
    "//         reject(err);\n",
    "//       }\n",
    "//       resolve(pass);\n",
    "//     });\n",
    "//   } else {\n",
    "//     resolve(existingApiKey);\n",
    "//   }\n",
    "// });\n",
    "\n",
    "// import getpass from \"https://deno.land/x/getpass/mod.ts\";\n",
    "\n",
    "// const apiKey = getpass();\n",
    "\n",
    "let apiKey: string | undefined | null = Deno.env.get('OPENAI_API_KEY');\n",
    "\n",
    "if (!apiKey) {\n",
    "  apiKey = prompt(\"Enter your OpenAI API key ðŸ”‘\");\n",
    "}\n",
    "\n",
    "if (!apiKey) {\n",
    "  throw new Error(\"No OpenAI API key found\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const client = new OpenAI({\n",
    "  apiKey,\n",
    "});\n",
    "\n",
    "async function main() {\n",
    " try {\n",
    "  const chatCompletion = await client.chat.completions.create({\n",
    "    messages: [{ role: 'user', content: 'Say this is a test' }],\n",
    "    model: 'gpt-3.5-turbo',\n",
    "  });\n",
    "  console.dir(chatCompletion.choices[0].message);\n",
    " } catch (e) {\n",
    "   console.error(e);\n",
    " }\n",
    "}\n",
    "\n",
    "await main();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
